\section{Database of Division by Station}
\label{sec:a1950.divibyStation}

After we filled in all missing values, we start our decomposition analysis with 
time dimension. In order to extract the seasonal and trend components for each 
observation, we construct the second database, from the initial database, of 
division by station for the data after 1950. In the following, we describe the 
details about the procedure of creating this division by station database.

\begin{description}
  \item[Input] 10,042,500 key-value pairs from the initial database, with one of
  unique 8,125 \texttt{station.id} and one of 1,236 months together as the key, 
  and a one-row R data.frame as the value. 
  \item[Output] division by station in form of 7,738 key-value pairs, with 
  \texttt{station.id} as the key, and R data.frame containing 576 observations 
  of corresponding station as the value.
  \item[Map]First input key-value pairs whose key contains year larger than 1950
  are filtered out. Next we change the key from a vector of \texttt{station.id} 
  and month index to \texttt{station.id} only. 
  \item[Reduce] 576 of one-row data.frame corresponding to one station are 
  aggregated to be one data.frame. Concretely all one-row data.frame who share
  the same \texttt{station.id} are shuffled and transferred to one reducer, and 
  then R function \texttt{rbind} is called in that reducer to combine those one-row 
  data.frame, which includes (1) \texttt{year}, year of the observation, 
  (2) \texttt{month}, month of year (January to December), (3) \texttt{tmax}, 
  the monthly maximum temperature, (4) \texttt{latitude}, (5) \texttt{longitude}, 
  and (6) \texttt{elevation}. We filter out stations who does not have any valid
  observation in 576 months. So finally there are 7,738 key-value pairs have been
  generated and save on HDFS. 
\end{description}


\subsection{Seasonal Trend Decomposition with \texttt{stlplus}}
\label{sec:a1950.stl}

As we discussed in section~\ref{sec:stl}, Seasonal Trend Loess decomposition is 
a very powerful procedure that can capture seasonality and long term trend in a
given time series. But what if we have multiple time series like different 
locations as in the dataset? Fortunately, by using RHIPE, which integrates the R 
and Hadoop, the division by station and the STL analysis on each station can be 
handily accomplished. On the one hand, R provides analysis friendly data structure 
and powerful statistical analysis and visualization packages such as 
\texttt{stlplus}, \texttt{lattice} package. On the other hand, Hadoop enables the
efficient processing of divisions, and facilitates the STL procedure in parallel
for time series in multiple locations. 

In the following, we illuminate in details the procedures to implement the parallel
STL in a MapReduce job generated by RHIPE on a cluster of 10 servers and 200 
processors.


\begin{description}
  \item[Input] 7,738 key-value pairs from the by station database generated in 
  section~\ref{sec:a1950.divibyStation}, with one of unique 7,738 
  \texttt{station.id} as the key, and a R data.frame with 576 rows as the value.
  Each row is one observation of a month at that given station. 
  \item[Output] Same key-value pairs, except that the value of each pair includes
  three new columns: \texttt{seasonal}, \texttt{trend}, and \texttt{remainder} 
  for each observation.
  \item[Map] For each input key-value pairs, we pass into \texttt{stlplus}
  function the observation column and time column in the data.frame of value, as
  well as a group of predefined smoothing parameter, which are \texttt{s.window},
  \texttt{s.degree}, \texttt{t.window}, \texttt{t.degree}, \texttt{inner}, and
  \texttt{outer}. The result of \texttt{stlplus} is a new data.frame which 
  includes \texttt{seasonal}, \texttt{trend}, \texttt{remainder} three new columns
  comparing with the input value. The new data.frame is saved with key as the 
  intermediate key-value pairs.
  \item[Reduce] No Reduce step is needed. The intermediate key-value pairs are 
  directly copied to HDFS.
\end{description}

Theoretically, we can pass into different smoothing parameters for different 
stations. But here, we start with same group of smoothing parameters for all 
stations. Intuitively, we would like to define those parameters for 
\texttt{stlplus} function only once, and then just simply make them available to
all stations. RHIPE implements this in a way that we define these smoothing 
parameters in a R list object in the Global environment of the master R session,
and then this R list will be copied onto HDFS and then copied to each mapper.

\subsubsection{s.window = 21, s.degree = 1, t.window = 231, t.degree = 2}
\label{stlplus1}

The first group of smoothing parameter we chose is considering local linear 
fitting for seasonal component, but local quadratic polynomials for trend 
components. The smoothing span for seasonal
component is set to be 21 which is 44\% of the total number of observations in 
each subseries. And smoothing span for trend component is 451, about 78\% of total
observations. Meanwhile we set the iteration time of inner loop to be 4 and 
outer loop to be 1. The fit is evaluated using diagnostic visualization methods
as following. 

The first visualization display demonstrates the fitted value against month. In 
Figure \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.stlraw.vs.time.pdf}
{\ref*{a1950.fitted.vs.time}}, each page is one of the 512 sampled stations. The 
whole time series with 576 time points for each station is chunked into 6 visual 
panels, each of which has 108 observations. The spatial imputed values are drawn 
with blue points, and the seasonal component plus trend component are drawn with
magenta curve.  

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.stlraw.vs.time.pdf}
  {Link to figure}
  \captionof{figure}{The fitted value vs. month}
  \label{a1950.fitted.vs.time}
\end{center}
\end{framed}

Collectively, no matter where the station is, the temporally fitted value 
(seasonal+trend) can capture the temporal pattern of each station, especially the
temporal seasonality. Next, we carry out the diagnostics for each components 
based on corresponding diagnostic plots.

Figure 
\href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.searemainder.vs.year.pdf}
{\ref*{a1950.searemainder.vs.year}} is called $seasonal$ $fitted$ $values$ $plot$
\cite{hafen2010local}, in which seasonal plus remainder component with mean of 
seasonal subtracted is drawn against to year. A magenta curve of centralized 
seasonal component is superposed on each panel. The reason for subtracting the 
mean is to center the values on each panel at zero; note that the vertical scales 
of all panels of all stations are the same so that we can graphically compare the 
variation of values on different panels.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.searemainder.vs.year.pdf}
  {Link to figure}
  \captionof{figure}{The seasonal fitted values vs. year}
  \label{a1950.searemainder.vs.year}
\end{center}
\end{framed}

It is noticeable that a larger smoothing window of seasonal component might be 
considered since too much variation is included in the seasonal component as
shown in Figure 
\href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.searemainder.vs.year.pdf}
{\ref*{a1950.searemainder.vs.year}}. 
Also as shown in Figure
\href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.remainder.vs.year.pdf}
{\ref*{a1950.remainder.vs.year}}, the remainder is plotted in $seasonal$ 
$residual$ $plot$ \cite{hafen2010local} against to year with a superposed loess 
smoothing line. The loess smoothing line here can be helpful to judge the lack
of fit for the seasonal component. Clearly, there is not any lack of fit problem
left in the remainder over all stations since loess smoothing line are all around
horizontal line at zero.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.remainder.vs.year.pdf}
  {Link to figure}
  \captionof{figure}{The seasonal residual vs. year}
  \label{a1950.remainder.vs.year}
\end{center}
\end{framed}


In Figure \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.trend.vs.time.pdf}
{\ref*{a1950.trend}}, the trend component of one station is drawn against to 
month in blue curve in each panel. In order to optimize the perception of the 
trend curve, we include 12 panels on one page, which follows the 45 degree banking
rule \cite{clevelandvisualizing}. However this sacrifices the room in each panel
which make the visual assessing of trend component harder if including all 
remainder of each station in corresponding panel. So instead of superposing the
remainder on each panel, the moving average of yearly mean of monthly 
maximum temperature is superposed on each panel as magenta points, which can 
help in judging the bias-variance trade-off of trend fitting.
Collectively, the same $stlplus$ parameter setting still can capture the different
trend behavior across all different stations, while a larger span window or lower
degree polynomial may be considered for trend smoothing since too much variation
has been captured by trend.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.trend.vs.time.pdf}
  {Link to figure}
  \captionof{figure}{The trend components vs. month}
  \label{a1950.trend}
\end{center}
\end{framed}

Remainder against to month is plotted for each station with a loess smoothing 
line superposed on each page in Figure 
\href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.remainder.vs.time.pdf}
{\ref*{a1950.remainder}}. This diagnostic plot can help us to assess lack of fit
or if there is any pattern left in remainder. Notably loess smoothing line in 
magenta color of each station is flat and close to horizontal reference line at 
zero.  

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t231td2_s21sd1_ffd/a1950.remainder.vs.time.pdf}
  {Link to figure}
  \captionof{figure}{The remainder vs. month}
  \label{a1950.remainder}
\end{center}
\end{framed}

Consequently, we observed high-variance estimate for both seasonal and trend
component with current smoothing parameters of $stlplus$. In the next fitting, we
consider a larger smoothing span with lower polynomial degree to eliminate extra
variation captured in these two components. 

\subsubsection{s.window = 41, s.degree = 1, t.window = 241, t.degree = 1}

Now local linear fitting is considered for both seasonal and trend components. 
Smoothing span for seasonal component is enlarged to 41, and smoothing span for 
trend component is kept at 241. Similarly we assess the smoothing fitting of two
component by visually diagnostic plots with the remainder.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.stlraw.vs.time.pdf}
  {Link to figure}
  \captionof{figure}{The fitted value vs. month}
  \label{a1950.fitted.vs.time2}
\end{center}
\end{framed}

As shown in Figure
\href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.stlraw.vs.time.pdf}
{\ref*{a1950.fitted.vs.time2}}, $stlplus$ fitted value as magenta line with 
superposed spatial smoothed input value as blue points. Collectively, the temporal
fitted value captures the seasonal and overall trend in each time series of 
different stations. Some of stations in California, such as stations with ID 
$047905$ and $047807$, they are located in the coast region and do not have very
strictly seasonality compared with other regions. So the difference between the
valley and peak of temporal fitted value is much smaller than other stations.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.searemainder.vs.year.pdf}
  {Link to figure}
  \captionof{figure}{The seasonal fitted values vs. year}
  \label{a1950.searemainder.vs.year2}
\end{center}
\end{framed}

In Figure 
\href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.searemainder.vs.year.pdf}
{\ref*{a1950.searemainder.vs.year2}}, centralized seasonal plus remainder 
component is drawn against to year as blue points, centralized seasonal component
is superposed as magenta curve as before. Appropriate amount of variation is 
filtered out from the seasonal component. We also notice that seasonal component
of maximum temperature kept increasing over time for March consistently and 
decreasing for October over majority of locations. In the Summer months, the 
corresponding seasonal component is collectively flat over all locations except 
the west coast region in California State, which have very unique and different
seasonality behavior than other locations.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.remainder.vs.year.pdf}
  {Link to figure}
  \captionof{figure}{The seasonal residual vs. year}
  \label{a1950.remainder.vs.year2}
\end{center}
\end{framed}

Even though the span window is enlarged to eliminate variation captured by 
seasonal smoothing, lack of fit does not exist. According to Figure 
\href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.remainder.vs.year.pdf}
{\ref*{a1950.remainder.vs.year2}}, the loess smoothing line of remainder
superposed in each month is still roughly flat and around horizontal zero line.

Besides the seasonal diagnostic plots, the Figure 
\href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.trend.vs.time.pdf}
{\ref*{a1950.trend2}} demonstrates the estimated trend component against to month
of one station in each panel. The integer index for each panel indicates the cell
of kd-tree (as shown in Figure \href{../plots/vertices.a1950.pdf}
{\ref*{a1950.vertices}}) in which the station is locating. Compared with estimated
trend component shown in previous subsection, more variation has been filtered 
out from the trend component. Same smoothing parameter collectively captured 
various pattern of trend at different locations. But it is interesting to notice
that stations closed to each other do have similar pattern of trend.


\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.trend.vs.time.pdf}
  {Link to figure}
  \captionof{figure}{The trend components vs. month}
  \label{a1950.trend2}
\end{center}
\end{framed}

Still, the remainder of station is drawn against to month with superposed loess
smoothing line one each page of the following Figure~
\href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.remainder.vs.time.pdf}
{\ref*{a1950.remainder2}}. The flat loess smoothing line around horizontal zero
reference line indicates that there is not sever lack of fit issue for the trend
estimate with a wider smoothing span and lower smoothing degree.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.remainder.vs.time.pdf}
  {Link to figure}
  \captionof{figure}{The remainder vs. month}
  \label{a1950.remainder2}
\end{center}
\end{framed}

Finally, we also would like to check the distribution of remainder of each 
station. This diagnostic plot can assist us to quickly judge if there is any 
outliers issue exists.

\begin{framed}
\begin{center}
  \href{../plots/a1950/stlplus/t241td1_s41sd1_ffd/a1950.QQ.remainder.pdf}
  {Link to figure}
  \captionof{figure}{The normal quantile plot of remainder}
  \label{a1950.QQremainder2}
\end{center}
\end{framed}


\subsection{Tuning Parameters of Seasonal Trend Loess}

In order to decompose the trend and seasonal components from each observation, we 
fit \texttt{stlplus} on the time series of each station independently. However,
according to the literature of \texttt{stl} and \texttt{stlplus}, there is not 
any rule of thumb about choosing of smoothing parameters $w_s$, $w_t$, $d_s$, and 
$d_t$. So a data-driven approach to tun the parameters is considered. 

Concretely, we are trying to use consecutive 270 observations, which is about 
50\% of the total number of observation for each station, as training 
data to predict oncoming 36 observations which treated as testing data. Then the 
loss function between the prediction and the true observation is calculated to 
measure the prediction ability. Concretely, for 
each station, we use the first 270 observations to predict 36 oncoming 
observations (271st to 306th). Then the time window of training dataset is moved 
one observation ahead (2nd to 271st), and prediction of the next 36 observations 
is produced. We call one run of prediction of 36 testing data as one replicate. 
Since there are 576 observations for each station, we conduct 271 replicates for 
prediction of 36 observations within each station.

Then, we want to find the best parameter set based on the prediction ability,
which is accuracy measurement. 
There are many measurements which all have their strength and weakness. 
Research indicates that the performances of different methods are related to the
purpose of forecasting and the specific concerns of the situation using the 
forecasts. 
That is why from a theoretical point of view there is no single best method 
\cite{brockwell2002introduction}.
$$
Error = | y_i - \hat y_i |
$$
where $y_i$ is the observation at $i$th month, and $\hat y_i$ is prediction value
which is equal to the summation of seasonal and trend components at $i$th month.

The criteria to judge the different measurements refers to the reliability and
discrimination of a method. Reliability is defined as the capability of producing 
consistent results when the methods are applied to different subsamples of the 
same series. Discrimination is the ability to tell apart better or worse models. 
Since it is not possible to optimize these criteria at the same time, trade-off 
should be considered.

The usual choice: 
Mean Squared Error is not suitable in this case because it is influenced by the 
outliers significantly. Our series are unique in that there is fair share of 
outliers. MSE gives too much weights to the outliers and the entire loss function is
dominated by the extreme outliers in this dataset. The regular positions in the 
pattern contribute to the loss function only negligibly. What we want is a robust
solution. The absolute prediction error does not discriminate against the regular
values and limits the influence of the extreme outliers, which provides robustness 
in the assessment of the performance. On the other hand, all of the outliers are 
on the lower end of the data range. The absolute value of the error makes sure 
the influence from positive and negative errors are treated equally.

The factors we are going to tun are $w_t$, $w_s$, $d_t$, 
and $d_s$. Within each factorial experiment, we conduct multiple STL fitting with 
different parameter set for some given factors, and we define the group index of 
parameter setting to be variable \texttt{group}. For example, in the Experiment 1,
the factors we choose is $w_s$ and $w_t$, each of which has three levels. The 
total number of group of parameter setting is 9.

\subsubsection{Generating Database for Experiment}
\label{sec:a1950.stlexp}

If we conduct the above experiment in series, we have to run 
$271 \times 7738 = 2096998$ number of STL fitting for all stations in R, which is 
extremely computational inefficient. Fortunately, because of using RHIPE
(R and Hadoop Integrated Programming Environment), we can easily handle this 
experiment in parallel. Intuitively, we carry out the STL fittings of multiple 
stations in parallel. Concretely, based on database of division by station, map
function which executes 271 STL prediction is applied to each of 7,738 station.
However, this is still computationally heavy for each mapper since all 271 STL 
fitting have to be sequentially executed in R with either \texttt{for} loop or 
\texttt{lapply} function. We have to consider other more efficient parallel 
procedure for the experiment.

There are two ways to carry out the parallel procedure, which are less 
heavy with respect to computation of each mapper. One is to create a share
R object, namely a data.frame containing all 576 observations of all 7,738 
stations, and it is saved on HDFS immediately after the MapReduce job is 
initialized. The data.frame is order by \texttt{station.id}, \texttt{year}, and
\texttt{month}. Then in the MapReduce job, we simulate the key of input key-value
pairs to be sequence of integer from 1 to 2,096,998, each of which represents the
row index of the first observation of each STL fitting. The corresponding value 
is the same integer as the key. For instance, if key-value pair is 
\texttt{(3001,3001)}, it means the corresponding map function applied to this 
key-value pair will use observations from August 1951 to Jan 1974 (20th observation
to 289th observation inclusively) to predict the maximum temperature of Feb 1974
to Jan 1977 for the 12th station.

But this method requires each mapper, which executes map function, to load the
shared R data.frame into memory of the worker on which the mapper is running. So
if one worker of the MapReduce job is assigned with multiple mappers, that shared
R object is loaded into memory with multiple copies which is inefficient with
respect to memory usage. As a result, we consider another way to perform the 
parallel computation. 

So the database we finally generated is based on 
by station database of dataset after 1950. We split one key-value pairs from by 
stations database to multiple key-value pairs in map function which we called 
FlatMap function. Specifically, the map function read in one key-value pairs, one
for each STL prediction fit. Totally, there are $2,096,998$ new key-value pairs 
saved on HDFS as the database for the experiments.

In what follows, we detail the procedure of generating experiment database in a 
MapReduce job.

\begin{description}
  \item[Input] 7,738 key-value pairs from the division by station database, with 
  \texttt{station.id} as the key, and R data.frame including 576 observations as
  the value.
  \item[Output] experiment database in form of 2,096,998 key-value pairs, with 
  vector of \texttt{station.id} and month index \texttt{i} of starting date of 
  training data as the key, and R data.frame containing 271 training data 
  observations and 36 testing observations as the value.
  \item[Map] For each input key-value pairs, we create 271 intermediate key-value
  pairs. We loop over month index \texttt{i} from 1 to 271, which represents the
  starting month of the training data. The key of intermediate key-value pairs
  is vector of \texttt{station.id} and \texttt{i}, the value contains 271 
  training data (starting from \texttt{i}th month) and 36 testing data, which is 
  a R data.frame with 307 rows and 7 columns.
  \item[Reduce] Identity reduce function do not do anything to the intermediate 
  key-value pairs besides evenly distributes all intermediate key-value pairs to 
  multiple files, and save them on HDFS.
\end{description} 

Next, we demonstrate the MapReduce job reading in above database from HDFS, and 
then process the STL fitting on each key-value pairs with one group of pre-defined 
parameters. 

\begin{description}
  \item[Input] 2,096,998 key-value pairs read from experiment database on HDFS.
  Key is vector of \texttt{station.id} and month index \texttt{i} of starting date
  of training data, and value is a data.frame including training data of 270 
  observations and testing data of the next 36 observations.
  \item[Output] Totally there are 7,738 multiplies total number of \texttt{group} 
  key-value pairs. 
  Key is vector of \texttt{station.id} and \texttt{group}; value is a R data.frame
  with $36 \times 271 = 9,756$ rows and 9 columns, which are (1) \texttt{year},
  (2) \texttt{month}, month of year, (3) \texttt{time}, the month index, (4) 
  \texttt{seasonal}, (5)\texttt{trend}, (6) \texttt{remainder}, (7) \texttt{tmax},
  (8) \texttt{lag}, prediction lag distance from 1 to 36, and (9) \texttt{rep},
  the replicates index of STL fitting, values from 1 to 271. 
  \item[Map] For each input key-value pairs, first we extend 270 training 
  observations with 36 \texttt{NA}s. And then pass this time series of 306 
  observations into R function \texttt{stl2} with pre-defined group of STL 
  parameter setting. Lastly a data.frame with 36 rows and 9 columns is generated
  as intermediate value, which includes the raw observations of the testing data, 
  as well as the prediction of \texttt{trend} and \texttt{seasonal} component of 
  the 36 months.
  \item[Reduce] Intermediate key-value pairs generated from map step will be saved
  on HDFS.
\end{description} 

In our design, we have four parameters in the parameter space: $w_t$, $w_s$, 
$d_t$ and $d_s$. In
every experiment, we fix the value of two factors and do a full factorial design
for anther two to explore and cover the design space. Besides, the number of inner
iterations and the number of outer iterations are also kept constant.

In the next several section, we detail the experiment set up, visualization for 
the diagnostics, and the parameter selection based on prediction error.

\subsubsection{Experiment 1,  
\textmd{$w_s=c(21, 30, 39)$, $w_t=c(231, 313, 451)$, $d_s=1$, $d_t=2$}
}

In the experiment 1, we vary the span window for seasonal and trend components. 
After the MapReduce job described previously, we first illustrate the distribution
of prediction residuals of each station for a given group of parameter setting
conditional on lag distance. Recall, in section~\ref{sec:a1950.divibyStation} we
randomly sampled 128 stations based on a kd-tree built on 7,738 stations. So we 
include these 128 stations in the graph for diagnostic purpose. Notice that there
are 1,152 ($128 \times 9$) pages of plots if one station is graphed one one page.
We describe the process of creating these graphs in parallel by using RHIPE in R
with \texttt{lattice} package.

\begin{description}
  \item[Input] $7,738 \times 9 = 69,642$ key-value pairs with vector of 
  \texttt{station.id} and \texttt{group} as the key, and value is a data.frame
  including the STL+ fitted value of seasonal and trend components of 36 lag 
  times 271 replicates for a given station given group of parameter setting.
  \item[Output] 9 PDF graph files, each of which is the Normal quantile plots of
  prediction residual conditional on lag distance for 128 stations for a given
  group parameter setting.  
  \item[Map] For each of input key-value pairs, we modify the key to be 
  \texttt{group} index only, which represent which parameter setting the STL fitting
  is based on. The value data.frame is added a new column named \texttt{station.id}.
  \item[Reduce] Intermediate key-value pairs, generated by map function, which 
  shares the same \texttt{group} index are shuffled and transfered into one reducer,
  and then are further aggregated into one data.frame by calling \texttt{rbind} 
  function in R. Then graphing function from \texttt{lattice} R package is utilized
  to generate PDF graph files based on each final key-value pair. However the 
  final key-value pairs are not saved on HDFS, but only the PDF files are save on
  HDFS. 
\end{description} 

The 9 PDF files are then copied from HDFS to the local file system to be 
visualized as in Figure {\ref{QQ.error.laggroup.E1}}. The parameter setting for
each group are
\\
group 1: $w_s = 21$, $w_t = 231$;
group 2: $w_s = 30$, $w_t = 231$;
group 3: $w_s = 39$, $w_t = 231$;\\
group 4: $w_s = 21$, $w_t = 313$;
group 5: $w_s = 30$, $w_t = 313$;
group 6: $w_s = 39$, $w_t = 313$;\\
group 7: $w_s = 21$, $w_t = 451$;
group 8: $w_s = 30$, $w_t = 451$;
group 9: $w_s = 39$, $w_t = 451$.
\\

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/QQ.error.tmax.group.1.pdf}{Link to group 1} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E1/QQ.error.tmax.group.2.pdf}{Link to group 2} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E1/QQ.error.tmax.group.3.pdf}{Link to group 3}
\end{center}
\begin{center}
  \href{../plots/a1950/E1/QQ.error.tmax.group.4.pdf}{Link to group 4} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E1/QQ.error.tmax.group.5.pdf}{Link to group 5} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E1/QQ.error.tmax.group.6.pdf}{Link to group 6}
\end{center}
\begin{center}
  \href{../plots/a1950/E1/QQ.error.tmax.group.7.pdf}{Link to group 7} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E1/QQ.error.tmax.group.8.pdf}{Link to group 8} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E1/QQ.error.tmax.group.9.pdf}{Link to group 9}
  \captionof{figure}{The normal quantiles of prediction error conditional on lag 
  for 128 stations with a given group of parameter setting in Experiment 1}
  \label{QQ.error.laggroup.E1}
\end{center}
\end{framed}

Each station is plotted on one page, and the order of the stations for a given 
group of parameter set up is decided as following: 
based on the normal quantile plot of prediction error for a given station across 
all 36 lag values, the total amount of deviation of the distribution of prediction 
error from normal distribution is calculated as
$$
Dev = \sum_{i=1}^{36} \sum_{j=1}^{271} |Error_{ij} - Z_{(j-0.5)/271}|^2
$$
where $Z_{(j-0.5)/271}$ is the $(j-0.5)/271$ quantiles of unit Normal distribution.
Then the stations are ordered from the smallest to the largest in term of 
deviation. Surprisingly, with a given parameter setting of \texttt{stlplus}, the
prediction error for all stations with different lag are well-approximated by
unit Normal distribution, which guarantee us to use the summary statistics, mean
and standard deviation of the prediction error for a given station and a given
lag to compare the prediction ability of different groups of \texttt{stlplus}
parameter setting. 

As we mentioned previously, we sampled 128 stations from the 7,738 stations for
the visualization purpose. The location of the 128 stations are shown in 
Figure \href{../plots/vertices.a1950.pdf}{\ref*{a1950.vertices}}. The index 1
to 128 is helpful to easily identify the stations. In Figure 
\href{../plots/vertices.a1950.pdf}{\ref*{a1950.vertices}}. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.absmeans.vs.lag.sw.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs. lag conditional on $w_s$}
  \label{e1.abserrorlag.sw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.std.vs.lag.sw.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $w_s$}
  \label{e1.stderrorlag.sw}
\end{center}
\end{framed}

In Figure \href{../plots/tmax.absmeans.vs.lag.sw.pdf}{\ref*{e1.abserrorlag.sw}}, 
the mean of absolute value of prediction error over 271 replicates for a given
station given lag distance is plotted against lag distance conditional on $w_s$ 
and superposed on $w_t$ with different color. Each page is for one station. Even
though 128 stations all come from very different locations, the prediction ability
of different parameter setting are surprisingly consistent. Within different 
$w_s$ values, trend window size with 451 always illustrates a lower prediction
error over 36 lag distance.
And in Figure \href{../plots/tmax.std.vs.lag.sw.pdf}{\ref*{e1.stderrorlag.sw}},
the standard deviation of prediction error multiplies 1.96 over 271 replicates 
for a given 
station given lag distance is plotted against lag distance conditional on $w_s$
and superposed on $w_t$. Again, trend window size with 451 returns the lowest
variance of error collectively. 
But we notice, the advantage of trend window size 451, with respect to the 
variance and mean of the prediction error, is negligible. 

Similarly, we plot the mean of absolute value of prediction error and standard 
deviation of prediction error, respectively, against to lag distance conditional 
on $w_t$ and superposed on $w_s$ as well.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.absmeans.vs.lag.tw.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs.lag conditional on $w_t$}
  \label{e1.abserrorlag.tw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.std.vs.lag.tw.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $w_t$}
  \label{e1.stderrorlag.tw}
\end{center}
\end{framed}

It is noticeable that within three different value of $w_t$, seasonal window size
39 provides the lowest mean and standard deviation of prediction error based on 
Figure 
\href{../plots/a1950/E1/tmax.absmeans.vs.lag.tw.pdf}{\ref*{e1.abserrorlag.tw}} 
and Figure 
\href{../plots/a1950/E1/tmax.std.vs.lag.tw.pdf}{\ref*{e1.stderrorlag.tw}}.
Moreover, three curves with different seasonal windows under given trend window 
are approximately parallel, and the range of standard deviation and mean of 
absolute value of prediction error over lag distance is negligible comparing to 
the value itself, we summarize the graphs above to make the comparison over 
different group parameter setting more straightforward.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.mean.absmeans.error.sw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $w_t$}
  \label{e1.abserror.sw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.mean.std.error.sw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $w_t$}
  \label{e1.stderror.sw}
\end{center}
\end{framed}

In Figure \href{../plots/tmax.mean.absmeans.error.tw.pdf}{\ref*{e1.abserror.sw}}
and Figure \href{../plots/tmax.mean.std.error.tw.pdf}{\ref*{e1.stderror.sw}}, 
the mean of absolute prediction error and the mean of standard deviation of 
prediction error of each station are plotted against the corresponding station
respectively, conditional on $w_s$ and superposed on $w_t$. Both standard 
deviation and mean of prediction error illustrates that prediction ability is
maximized when trend window size is 451. But we also notice that the difference
between different trend window size with respect to the prediction error is 
negligible cross all 128 stations. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.mean.absmeans.error.tw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $w_s$}
  \label{e1.abserror.tw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E1/tmax.mean.std.error.tw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $w_s$}
  \label{e1.stderror.tw}
\end{center}
\end{framed}

Similarly, in 
Figure \href{../plots/tmax.mean.absmeans.error.tw.pdf}{\ref*{e1.abserror.tw}}
and Figure \href{../plots/tmax.mean.std.error.tw.pdf}{\ref*{e1.stderror.tw}}, 
we plot the mean of absolute prediction error and the mean of standard deviation 
of prediction error of each station against the corresponding station conditional 
on $w_s$ and superposed on $w_t$. We also notice that even though seasonal window
size of 39 provides the best prediction ability with different trend window size,
the advantage is very small. This implies we should also enlarge the seasonal 
window.  

\subsubsection{Experiment 2,  
\textmd{$w_s=c(11, 41, $"periodic"$)$, $w_t=c(123, 241, 451)$, $d_t=2$}
}

In the experiment 2, we still vary the span window for seasonal and trend fitting,
but with a larger range for seasonal span window. The parameter setting for each 
group are
\\
group 1: $w_s = 11$, $w_t = 123$;
group 2: $w_s = 41$, $w_t = 123$;\\
group 3: $w_s = "periodic"$, $w_t = 123$;
group 4: $w_s = 11$, $w_t = 241$;\\
group 5: $w_s = 41$, $w_t = 241$;
group 6: $w_s = "periodic"$, $w_t = 241$;\\
group 7: $w_s = 11$, $w_t = 451$;
group 8: $w_s = 41$, $w_t = 451$;\\
group 9: $w_s = "periodic"$, $w_t = 451$;
\\
We include "periodic" as one 
of the value for seasonal window. "periodic" means for each sub-series, local 
weighted regression is conducted with span equal to infinite and degree equal to 
0. Infinite span window is actually same as global weighted regression with equal 
weight 1 for all points. And we make the rang of trend window to be more 
variable than experiment 1.
Again, we carry out the same MapReduce job as we demonstrated in the experiment
1 but with different 9 groups of parameter settings to visualize the normal 
quantiles of prediction error conditional on lag distance for 128 stations.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/QQ.error.tmax.group.1.pdf}{Link to group 1} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E2/QQ.error.tmax.group.2.pdf}{Link to group 2} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E2/QQ.error.tmax.group.3.pdf}{Link to group 3}
\end{center}
\begin{center}
  \href{../plots/a1950/E2/QQ.error.tmax.group.4.pdf}{Link to group 4} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E2/QQ.error.tmax.group.5.pdf}{Link to group 5} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E2/QQ.error.tmax.group.6.pdf}{Link to group 6}
\end{center}
\begin{center}
  \href{../plots/a1950/E2/QQ.error.tmax.group.7.pdf}{Link to group 7} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E2/QQ.error.tmax.group.8.pdf}{Link to group 8} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E2/QQ.error.tmax.group.9.pdf}{Link to group 9}
  \captionof{figure}{The normal quantiles of prediction error conditional on lag 
  for 128 stations with a given group of parameter setting in Experiment 2}
  \label{QQ.error.laggroup}
\end{center}
\end{framed}
The stations are ordered from the smallest to the largest in term of deviation
from the unit normal distribution. Still, the prediction error for all 128 
stations with different lag are well-approximated by unit Normal distribution.
As a result, we evaluate the prediction ability of each group of parameter setting
based on the mean of absolute value of prediction error and standard deviation of
prediction error collectively. However, there is one thing should be pointed out
which did not happen in the first experiment.
With group 1 to group 3 parameter setting, even though the distribution of mean
of absolute value of prediction error for each lag distance is approximated by
a unit Normal distribution, the variance of the unit Normal is enlarging when 
the lag distance becomes further. This implies that the prediction error is more
unstable when the $w_t$ is relatively small.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.absmeans.vs.lag.sw.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs. lag conditional on $w_s$}
  \label{e2.abserrorlag.sw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.std.vs.lag.sw.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $w_s$}
  \label{e2.stderrorlag.sw}
\end{center}
\end{framed}

This time, it is trivial to notice that the difference between trend window of 
123 and the other two value of trend window is significant in all three different 
values of seasonal window for all stations. But the curves for 313 and 451 of 
trend window are almost overlapping. These plots imply that the prediction ability
decrease when trend window is enlarged until a stable level after trend window 
is around 241.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.absmeans.vs.lag.tw.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs.lag conditional on $w_t$}
  \label{e2.abserrorlag.tw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.std.vs.lag.tw.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $w_t$}
  \label{e2.stderrorlag.tw}
\end{center}
\end{framed}

In Figure 
\href{../plots/a1950/E2/tmax.absmeans.vs.lag.tw.pdf}{\ref*{e1.abserrorlag.tw}} 
and Figure 
\href{../plots/a1950/E2/tmax.std.vs.lag.tw.pdf}{\ref*{e1.stderrorlag.tw}},
the prediction ability varies apparently between different seasonal span window
cross three trend windows for all stations. "periodic" seasonal window gives
the lowest prediction error collectively in all stations. Moreover, we also notice
that when trend span window is 123, the mean and standard deviation of prediction
error increasing dramatically when lag distance increasing. This also confirms
our finding for the trend span window. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.mean.absmeans.error.sw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $w_t$}
  \label{e2.abserror.sw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.mean.std.error.sw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $w_t$}
  \label{e2.stderror.sw}
\end{center}
\end{framed}

In Figure 
\href{../plots/a1950/E2/tmax.mean.absmeans.error.sw.pdf}{\ref*{e2.abserror.tw}} 
and Figure 
\href{../plots/a1950/E2/tmax.mean.std.error.sw.pdf}{\ref*{e2.stderror.tw}}, trend
span window equal to 123 collectively has undoubtedly higher mean of absolute 
value and standard deviation of the prediction error cross all stations. But there
is not clearly difference after trend span window larger than 241 with respect
to prediction error.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.mean.absmeans.error.tw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $s_t$}
  \label{e2.abserror.tw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E2/tmax.mean.std.error.tw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $s_t$}
  \label{e2.stderror.tw}
\end{center}
\end{framed}

\subsubsection{Experiment 3,  
\textmd{$w_s=$"periodic", $w_t=c(41, 83, 123, 241, 451)$, $d_s=1$, $d_t=c(1,2)$}
}
In the third experiment, we vary the trend span window with 5 different values, 
from 41 to 451, much wider range than the first two experiments, and trend
degree with 2 values, local linear or local quadratic. So totally there are 10
runs in the experiment.
\\
group 1: $w_t = 41$, $d_t = 1$;
group 2: $w_t = 83$, $d_t = 1$;
group 3: $w_t = 123$, $d_t = 1$;\\
group 4: $w_t = 241$, $d_t = 1$;
group 5: $w_t = 451$, $d_t = 1$;
group 6: $w_t = 41$, $d_t = 2$;\\
group 7: $w_t = 83$, $d_t = 2$;
group 8: $w_t = 123$, $d_t = 2$;
group 9: $w_t = 241$, $d_t = 2$;\\
group 10: $w_t = 451$, $d_t = 2$;
\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/QQ.error.tmax.group.1.pdf}{Link to group 1} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E3/QQ.error.tmax.group.2.pdf}{Link to group 2} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E3/QQ.error.tmax.group.3.pdf}{Link to group 3}
\end{center}
\begin{center}
  \href{../plots/a1950/E3/QQ.error.tmax.group.4.pdf}{Link to group 4} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E3/QQ.error.tmax.group.5.pdf}{Link to group 5} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E3/QQ.error.tmax.group.6.pdf}{Link to group 6}
\end{center}
\begin{center}
  \href{../plots/a1950/E3/QQ.error.tmax.group.7.pdf}{Link to group 7} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E3/QQ.error.tmax.group.8.pdf}{Link to group 8} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E3/QQ.error.tmax.group.9.pdf}{Link to group 9}
\end{center}
\begin{center}
  \href{../plots/a1950/E3/QQ.error.tmax.group.10.pdf}{Link to group 10}  
  \captionof{figure}{The normal quantiles of prediction error conditional on lag 
  for 128 stations with a given group of parameter setting in Experiment 3}
  \label{QQ.error.laggroup}
\end{center}
\end{framed}
This time we fix the seasonal span window to be "periodic" based on the finding
in previous experiments. The first batch of graphs are still the normal quantile
plots of prediction error for each station with different groups of parameter
settings. We notice that when $d_t$ is quadratic, the group 6 to group 8, which
$w_d$ is less than 123, the slop of normal quantile plot increases dramatically
as lag distance becomes farther. This means when we try to apply quadratic 
polynomial regression in a relatively small local time period, the prediction 
for longer lag distance turns to be more unreliable.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.absmeans.vs.lag.td.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs. lag conditional on $d_t$}
  \label{e3.abserrorlag.td}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.std.vs.lag.td.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $d_t$}
  \label{e3.stderrorlag.td}
\end{center}
\end{framed}

Mean of absolute prediction error and standard deviation error are plotted 
against lag distance conditional on $d_t$ and superposed on $w_t$ in the
Figure 
\href{../plots/a1950/E3/tmax.absmeans.vs.lag.td.pdf}{\ref*{e3.abserrorlag.td}} 
and Figure 
\href{../plots/a1950/E3/tmax.std.vs.lag.td.pdf}{\ref*{e3.stderrorlag.td}}. 
It is shown that mean of absolute prediction error and standard deviation of
prediction error
are minimized and become stable after $w_t$ is larger than 123. Moreover, when
$d_t$ is equal to 2, small value of $w_t$ makes the prediction error inflated
when lag distance is large. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.absmeans.vs.lag.tw.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs. lag conditional on $w_t$}
  \label{e3.abserrorlag.tw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.std.vs.lag.tw.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $w_t$}
  \label{e3.stderrorlag.tw}
\end{center}
\end{framed}

Figure 
\href{../plots/a1950/E3/tmax.absmeans.vs.lag.tw.pdf}{\ref*{e3.abserrorlag.tw}} 
and Figure 
\href{../plots/a1950/E3/tmax.std.vs.lag.tw.pdf}{\ref*{e3.stderrorlag.tw}} 
illustrate the mean of absolute prediction error and standard deviation of 
prediction error against lag distance conditional on $w_t$ and superposed on 
$d_t$ for each of 128 stations. It is noticeable that prediction error inflates
dramatically as lag distance goes up when the $w_t$ is 41 and $d_t$ is 1.
As $w_t$ is larger than 123. there is not significant difference between the 
local linear or quadratic fit for trend component.

We summarize the results in the third experiment by the dotplot of overall mean 
of absolute prediction error and mean of standard deviation of prediction error
against station conditional on $w_t$ ($d_t$) and superposed on $d_t$ ($w_t$). As
dedicated in Figure
\href{../plots/a1950/E3/tmax.mean.absmeans.error.td.pdf}{\ref*{e3.abserror.td}} 
and Figure 
\href{../plots/a1950/E3/tmax.mean.std.error.td.pdf}{\ref*{e3.stderror.td}}, 
conditional on $d_t$ value, the prediction error is minimized at $w_t$ of value 
241 collectively. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.mean.absmeans.error.td.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $w_t$}
  \label{e3.abserror.td}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.mean.std.error.td.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $w_t$}
  \label{e3.stderror.td}
\end{center}
\end{framed}

Figure 
\href{../plots/a1950/E3/tmax.mean.absmeans.error.tw.pdf}{\ref*{e3.abserror.tw}} 
and Figure 
\href{../plots/a1950/E3/tmax.mean.std.error.tw.pdf}{\ref*{e3.stderror.tw}}
demonstrate that local linear fit for trend component always provide the lowest
prediction error, especially for small value of $w_t$.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.mean.absmeans.error.tw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $s_t$}
  \label{e3.abserror.tw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E3/tmax.mean.std.error.tw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $s_t$}
  \label{e3.stderror.tw}
\end{center}
\end{framed}

\subsubsection{Experiment 4,  
\textmd{$w_s=c(11, 21, 31, 47$,"periodic"$)$, $w_t=241$, $d_s=c(1,2)$, $d_t=1$}
}
In the fourth experiment, we vary the span window and polynomial degree for 
seasonal component $w_s$ and $d_t$, and fix the parameter for the trend 
component based on the result of previous experiment, which $w_d = 241$ and 
$d_t = 1$. Totally there are 9 runs in the experiment, since there is only one 
run for $w_s$ is "periodic".
\\
group 1: $w_s = 11$, $d_s = 1$;
group 2: $w_s = 21$, $d_s = 1$;
group 3: $w_s = 31$, $d_s = 1$;\\
group 4: $w_s = 47$, $d_s = 1$;
group 5: $w_s = "periodic"$, $d_s = 1$;\\
group 6: $w_s = 11$, $d_s = 2$;
group 7: $w_s = 21$, $d_s = 2$;
group 8: $w_s = 31$, $d_s = 2$;\\
group 9: $w_s = 47$, $d_s = 2$;
\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/QQ.error.tmax.group.1.pdf}{Link to group 1} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E4/QQ.error.tmax.group.2.pdf}{Link to group 2} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E4/QQ.error.tmax.group.3.pdf}{Link to group 3}
\end{center}
\begin{center}
  \href{../plots/a1950/E4/QQ.error.tmax.group.4.pdf}{Link to group 4} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E4/QQ.error.tmax.group.5.pdf}{Link to group 5} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E4/QQ.error.tmax.group.6.pdf}{Link to group 6}
\end{center}
\begin{center}
  \href{../plots/a1950/E4/QQ.error.tmax.group.7.pdf}{Link to group 7} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E4/QQ.error.tmax.group.8.pdf}{Link to group 8} 
  \;\;\;\;\;\;\;\;\;\;
  \href{../plots/a1950/E4/QQ.error.tmax.group.9.pdf}{Link to group 9}
\end{center}
\begin{center}
  \captionof{figure}{The normal quantiles of prediction error conditional on lag 
  for 128 stations with a given group of parameter setting in Experiment 4}
  \label{QQ.error.laggroup}
\end{center}
\end{framed}

Collectively, the prediction error is well approximated by an unit Normal
distribution for given lag distance of each station with a given group of
parameter setting. However, in group 4, which $w_s$ is 11 and $d_s$ is 2, the 
variance of the prediction error for lag distance farther than 12 becomes larger
than that for shorter lag distance. Prediction is more unstable for longer lag
distance under this group pf parameter setting. Similar situation can also be
found in group 7 parameter setting, which is also has relatively small $w_s$ but
quadratic local fit for the seasonal component.

Then the mean of the absolute value of prediction error over each value of lag
distance for each station is plotted against to the lag distance on each page as
in Figure \href{../plots/a1950/E4/tmax.absmeans.vs.lag.sw.pdf}
{\ref*{e4.abserrorlag.sw}}. Clearly, with smaller value of s.window the MAPE 
consistently is much smaller with shorter lag distance within a year than it with
further lag distance. Moreover, this difference is amplified when s.degree is 
equal to 2. For example, 
in the first panel on the left hand side of each page, the MAPE increases 
drastically from the first year to the second year and then the third year when
s.degree is 2. And when the s.window is raised to a higher value, the MAPE 
becomes more stable over the value of lag distance until it is minimized when 
s.window is \texttt{periodic}.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.absmeans.vs.lag.sw.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs. lag conditional on $w_s$}
  \label{e4.abserrorlag.sw}
\end{center}
\end{framed}

Same phenomena can be found in the Figure 
\href{../plots/a1950/E4/tmax.std.vs.lag.sw.pdf}{\ref*{e4.stderrorlag.sw}}, which 
the standard deviation of prediction error multiplied by 1.96 is plotted against
to the value of lag distance. s.window of \texttt{periodic} gives the 
lowest and most stable standard deviation over all different setting of s.window
and s.degree over all 128 stations collectively. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.std.vs.lag.sw.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $w_s$}
  \label{e4.stderrorlag.sw}
\end{center}
\end{framed}

If we switch the conditional 
variable from s.window to s.degree, it is undoubted the \texttt{periodic} seasonal
component will be the best choice with respect to the prediction error. As shown
in Figure \href{../plots/a1950/E4/tmax.absmeans.vs.lag.sd.pdf}
{\ref*{e4.abserrorlag.sd}} and Figure 
\href{../plots/a1950/E4/tmax.std.vs.lag.sd.pdf}{\ref*{e4.stderrorlag.sd}}, there
is a dramatically difference between the \texttt{periodic} setting and smaller 
value of s.window for both MAPE and SDPE. Meanwhile, MAPE and SDPE from small 
value of s.window does not increased smoothly over the lag distance. There 
surely is a jump every 12 months of lag distance. So the prediction is not stable
over longer lag distance with smaller value of s.window compared with 
\texttt{periodic} seasonal component.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.absmeans.vs.lag.sd.pdf}{Link to figure}
  \captionof{figure}{The mean of abs error vs. lag conditional on $d_s$}
  \label{e4.abserrorlag.sd}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.std.vs.lag.sd.pdf}{Link to figure}
  \captionof{figure}{The standard deviation of error vs. lag conditional on $d_s$}
  \label{e4.stderrorlag.sd}
\end{center}
\end{framed}

Finally, we summarize the prediction error for each group of parameter setting
by the overall mean of absolute value of prediction error and the overall mean
of standard deviation of prediction error multiplied 1.96. In the Figure 
\href{../plots/a1950/E4/tmax.mean.absmeans.error.sw.pdf}{\ref*{e4.abserror.sw}}
and Figure \href{../plots/a1950/E4/tmax.mean.std.error.sw.pdf}
{\ref*{e4.stderror.sw}}, The overall MAPE and MSDPE respectively are plotted 
against to the corresponding station in order conditional on s.window and 
superposed on s.degree. Apparently, within a given value of s.window, local linear
fit consistently provides a lower value of overall MAPE and MSDPE over all 128 
stations. And the superiority of local linear fit is maximized when s.window is
11.

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.mean.absmeans.error.sw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $w_s$}
  \label{e4.abserror.sw}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.mean.std.error.sw.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $w_s$}
  \label{e4.stderror.sw}
\end{center}
\end{framed}

Similar conclusion can be also made if we switch the conditional variable from
s.window to s.degree, and overall MAPE and MSDPE is plotted against to 
corresponding station superposed on s.window, as in Figure 
\href{../plots/a1950/E4/tmax.mean.std.error.sw.pdf}{\ref*{e4.abserror.sd}} and 
Figure \href{../plots/a1950/E4/tmax.mean.std.error.sd.pdf}{\ref*{e4.stderror.sd}}.
\texttt{periodic} seasonal component overcome other value of s.window in both
local linear and quadratic fit.


\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.mean.absmeans.error.sd.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of abs error vs. station conditional on $d_s$}
  \label{e4.abserror.sd}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/E4/tmax.mean.std.error.sd.pdf}{Link to figure}
  \captionof{figure}{The dotplot of mean of standard deviation of error vs.station conditional on $d_s$}
  \label{e4.stderror.sd}
\end{center}
\end{framed}

In summary, we varied the s.window, s.degree, t.window, and t.degree four factors
to find the best prediction stlplus model with respect to the prediction error.
