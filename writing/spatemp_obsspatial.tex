\section{Database of Division by Month}

In the previous section, we illustrated the results of exploratory analysis. We 
also mentioned that subset after 1950 is mainly considered in the rest of the 
thesis. The first database we create for data after 1950 is called division 
by-month. In the following paragraph we describe the MapReduce job used to create 
such division with details.

\begin{description}
  \item[Input] 10,042,500 key-value pairs from the initial database, key is the
  vector with one of the combination of 8,125 unique \texttt{station.id} and  
  1,236 month index. The corresponding value is a one-row R data.frame. The value 
  includes \texttt{lon}, \texttt{lat}, \texttt{elev}, \texttt{year}, 
  \texttt{month}, and \texttt{tmax}.
  \item[Output] By-month division, in the form of 576 key-value pairs, with 
  \texttt{date}, month index, as the key, a R data.frame containing 
  observations from 7,738 stations in the corresponding month as the value.
  \item[Map]For every input key-value pair, we include a new column named 
  \texttt{station.id} to the data.frame, and remove the \texttt{year} and 
  \texttt{month} from the value to be the key of intermediate key-value pairs. 
  \item[Reduce] 7,738 of one-row data.frame corresponding to one month are 
  aggregated to be one data.frame. Specifically, all one-row data.frame who share
  the same \texttt{year} and \texttt{month} are shuffled and transferred to one 
  reducer, and then R function \texttt{rbind} is called in that reducer to combine 
  those one-row data.frames.
\end{description}

\subsection{Distance Calculation of Neighbors}

Before we start any discussion about the details of analysis procedure by month,
let us have a second thought on the distance calculation in the Loess method.
As we mentioned in section~\ref{sec:loess}, loess method calculates the weights 
$\omega_i(x)$
for weighted least square based on the distance of neighbors $x_i$ to the target 
point $x_0$. The distance calculation of $d(x_i, x_0)$ is based on Euclidean distance 
(in two dimension for example):
\begin{equation} 
d(x_i, x_0) = \| x_0 - x_i \|_2
\end{equation} 
In the spatial loess fitting, however, the Euclidean distance is apparently not 
appropriate. Because one unit increment in longitude degree is different than 
that in latitude degree \cite{banerjee2005geodetic}. A more reasonable and 
realistic distance definition in spatial dimension is the Great-circle distance, 
which is the shortest distance between two points on the surface of a sphere, 
measured along the surface of the sphere (as opposed to a straight line through 
the sphere's interior) \cite{greatcircle}. 

Explicitly, let $\phi_a$, $\lambda_a$ and $\phi_b$, $\lambda_b$ be the geographical 
latitude and longitude of two points $a$ and $b$, and $\Delta \phi$, 
$\Delta \lambda$ their absolute differences; then $\Delta \sigma$ the central angle 
between them, is given by:
\begin{equation} 
\Delta \sigma_{a,b} = 2 \arcsin \sqrt{ \sin^2 ( \frac{\Delta \phi}{2} ) + \cos 
\phi_a \cdot \cos \phi_b \cdot \sin^2 ( \frac{\Delta \lambda}{2} )}
\end{equation} 
Then the distance $d(a,b)$, i.e. the arc length, for a sphere of radius $r$ is
\begin{equation} 
d(a,b) = r \Delta \lambda_{a,b}
\end{equation} 

\subsection{Spatial Smoothing without Elevation}
\label{sec:impute.w/o.elev}

As a practical matter, for many of the stations, records from the previous and
following months are not available. 20 percent of stations have consecutive 
missing periods longer than a year. It is more reasonable and
feasible to start the analysis by applying spatial loess against to longitude and 
latitude to the by-month division as we generated above. By doing this, missing 
value can be reasonable infilled using observations in their neighborhood in each 
month. Specifically, a kd-tree \cite{bentley1980multidimensional} is built based 
on the location of all 7,738 stations. Spatial loess fitting is carried out at
each vertex of the kd-tree based on the Great-circle distance. And then cubic 
interpolation is proceeded at all stations. For the spatial loess, the smoothing
neighborhoods are small, since the purpose of this fitting is to eliminate 
spatial noise and infill missing values. Over smoothing is much worse than 
under smoothing in this case.   
Moreover, fitting in each month are carried out independently in parallel using 
database of division by-month as input, and generate a new by-month division with 
spatial smoothed value.

Next we illustrate the MapReduce job which proceeds the spatial smoothing in 
parallel.
\begin{description}
  \item[Input] 576 key-value pairs of by month division. Key is \texttt{date}; 
  value is a data.frame object with 7,738 number of rows, each of which is 
  observation for one station.
  \item[Output] 576 key-value pairs. Key is same as input, and value is still
  a data.frame but with an added column of spatial smoothed value, named 
  \texttt{spaofit}. 
  \item[Map]For every input key-value pair, \texttt{spaloess} function is applied
  to the maximum temperature at 7,738 stations with their longitude and latitude 
  as independent variables.
  \item[Reduce] Reduce is not needed in this MapReduce job.
\end{description}

In the map step, the spatial loess smoothing is executed by function from a new 
R package named \texttt{Spaloess}. This package is wrote based on the 
\texttt{loess} function in the base R. The original loess implementation in R, 
named as \texttt{loess}, only allows Euclidean distance when calculated the 
weights for neighbors. Moreover, the kd-tree is built excluding missing values, 
which can be a problem for interpolation if the missing values are at location 
outside the range or area covered by the valid observations used to build the 
kd-tree. Also the missing values cannot be predicted without another call of 
\texttt{predict} function. More details about the \texttt{Spaloess} package will 
be discussed in section~\ref{sec:Rpackage}.

There are two smoothing parameters needed to be specified in the spatial loess, 
which are span controlling the number of neighbors used in the local regression 
fit, and degree controlling the polynomial degree of the regression. The 
smoothing result can be evaluated based on the diagnostic plots which can be 
generated in parallel. Overall, there are two types of visual graph to assess the
spatial spatial smoothing. The first type is one visual display for each year. 
Visualization of twelve months in a given year is plotted on one page with twelve 
panels. The layout of panels maybe different depends on the character of 
visualization itself. 

Next we illustrate the MapReduce job which generates the first type of visual 
graph in parallel.

\begin{description}
  \item[Input] 576 key-value pairs of by-month division. Key is \texttt{date}; 
  value is a data.frame object with 7,738 number of rows, which includes original
  observation of maximum temperature and the spatial smoothed value. 
  \item[Output] 48 key-value pairs. Key is \texttt{year}, and value is a serialized
  trellis object for a given year created by \texttt{serialize} function.
  \item[Map]For every input key-value pair, the key is changed from \texttt{date} 
  to \texttt{year} only. The value is kept the same as input. Also the residual 
  of spatial smoothing for each station is calculated.
  \item[Reduce] Intermediate key-value pairs who share the same \texttt{year} are
  shuffled and sent to one reducer, and then twelve data.frame are row-binded 
  together accumulatively. A predefined plotting engine function based on 
  functions in \texttt{lattice} package is passed into each reducer and apply to 
  the accumulated data.frame, which generates a \texttt{trellis} object for each 
  year. In the end, \texttt{serialize} function is applied to the trellis object 
  and saved on HDFS.
\end{description}

As we will see later in Figure 
\href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResidcenter.bytime.pdf}
{\ref*{nonelev.0.05.Residcenter.bytime}} which belongs to the first type of 
visualization, \texttt{trellis} object of each year is generated on one page in 
the Reduce step by calling a specific visualization function in \texttt{lattice} 
package, for example, \texttt{xyplot} or \texttt{qqmath}.

The Second type of visualization is to assess the spatial smoothing for one of 
576 month on each page. Specifically, a serialized \texttt{trellis} object is 
created for each month. We illustrate this in the next MapReduce job.

\begin{description}
  \item[Input] 576 key-value pairs of by month division. Key is a vector of
  \texttt{year} and \texttt{month}; value is a data.frame object with 7,738 
  number of rows, which includes original observation of maximum temperature
  and the spatial smoothed value. 
  \item[Output] 576 key-value pairs. Key is same as input, and value is a 
  serialized trellis object created by \texttt{serialize} function.
  \item[Map]For every input key-value pair, a predefined plotting engine function
  based on functions in \texttt{lattice} package is passed into the mapper and 
  apply to each value, which generate a \texttt{trellis} object for each 
  key-value pair. Then \texttt{serialize} function is applied to the trellis 
  object in order to save it as the value of intermediate key-value pairs.
  \item[Reduce] Reduce is not needed in this MapReduce job. Intermediate key-value
  pairs are directly save to HDFS.
\end{description}

\subsubsection{span = 0.05 and degree = 2}

In the first run, we specify the span of spatial loess to be 0.05, which means
for each station, spatial smoothed value is calculated by using 5 percent of 
valid observation in its neighborhood. And the polynomial degree of spatial loess 
fit is set to be quadratic.

\begin{framed}
\begin{center}
  \href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResidcenter.bytime.pdf}
  {Link to figure}
  \captionof{figure}
  {The normal quantiles between 0.015 and 0.985 of residual of spatial spatial 
  smoothing}
  \label{nonelev.0.05.Residcenter.bytime}
\end{center}
\end{framed}

For each month, there are around 5,000 spatial smoothing residuals. 971 quantiles 
of the spatial smoothing residuals, from 0.015 to 0.985, are plotted against to 
their corresponding unit Normal quantiles in Figure 
\href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResidcenter.bytime.pdf}
{\ref*{nonelev.0.05.Residcenter.bytime}}. Notice that the range of the residual
for each month is from -5 to 5 collectively, and it has longer tail compared with
unit Normal distribution. Besides the Normal quantile plot, another type of 
diagnostics plot to assess the spatial smoothing is the scatter plot of residual 
against to one of the predictor variables conditional on the other one, 
specifically longitude and latitude, which will be shown in the following. As in 
Figure
\href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResid.vs.lat.lon.pdf}
{\ref*{nonelev.0.05.Residvslat.lon}}, when longitude is being conditional on, it
is equally cut into categorical variable with 20 intervals. Then spatial smoothing 
residual is plotted against to latitude in each category of longitude. Also a 
loess smoothing curve, with span is equal to 0.25 and degree is equal to 1, is 
added to help us assess the overall trend of the residuals. The loess smoothing 
curve is collectively around the horizontal reference line at zero over all month. 
However, it is noticeable that most of large negative residuals are
regularly show up in the first five panels over all months. The first five panels
are for the longitude from -124.7 to -110.9 degree. Recall that this region is
the Rocky Mountains where the elevation is various dramatically.
Moreover, there is an outlier with relatively large negative residual consistently 
in the panel with largest longitude. The corresponding location of this outlier
is station \texttt{275639} with elevation 1909 meters, longitude -71.30 degree
and altitude 44.27 degree. An extremely important fact with respect to this
station is that it is the only station with elevation above 1200 meters among
643 stations in its neighborhood in the northeastern corner of the United States. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResid.vs.lat.lon.pdf}
  {Link to figure}
  \captionof{figure}
  {The residual of spatial spatial smoothing against to latitude conditional on 
  longitude}
  \label{nonelev.0.05.Residvslat.lon}
\end{center}
\end{framed}

Same information can be found in Figure 
\href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResid.vs.lon.lat.pdf}
{\ref*{nonelev.0.05.Residvslon.lat}} as well. Variation of the residual is wider
in the west side of United State compared with east side cross all the 20 different
levels of latitude degree. Again the station \texttt{275639} with elevation 1909 
meters can be found in the 17th panel of latitude. Another group of outliers can 
be found in the 6th panel of latitude, which is in the region of 35.5 to 36.5 degree, 
around longitude -82 degree. It is the region of Appalachian Mountains.

\begin{framed}
\begin{center}
  \href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResid.vs.lon.lat.pdf}
  {Link to figure}
  \captionof{figure}
  {The residual of spatial spatial smoothing against to longitude conditional on latitude}
  \label{nonelev.0.05.Residvslon.lat}
\end{center}
\end{framed}

Intuitively, we want to illuminate the amount of bias in the spatial smoothing. We have 
to sacrifice the variation in the bias-variance trade-off of the local regression
method. Meanwhile, elevation is another potential critical predictor variable to
impute the maximum temperature based on the diagnostics plots above.
Consequently, we need to consider a new spatial smoothing model which includes elevation as
one of the predictor variables, also shrink the span value to illuminate the 
bias in the spatial smoothing.

\subsection{Spatial Smoothing with Elevation}

As we mentioned previously, elevation should be considered to be included in the 
local regression model. However, more thoughts should be given to the distance 
calculation when elevation is added into the model. If we simply add elevation
in the local regression model directly, the calculation of weights of neighbors
needs modification based on the three-dimension predictor space. However, the 
definition of distance in this three-dimension space is not trivial, since the
temperature is not isotropic in the vertical and horizontal direction. As a 
result, Euclidean distance in three-dimension space is not appropriate for this
situation. Meanwhile, it is more intuitively to assume that the neighborhood or
distance to neighbors are defined only based on longitude and latitude, as the
weights introduced in Geographically Weighted Regression \cite{fotheringhamGWR}.
In the next subsection, we will describe a way to include elevation variable as
a global parameter into the local regression model.

\subsubsection{Conditionally Parametric Model}

The conditionally parametric fit, introduced in \cite{cleveland1992local}, provides
a generalization of the semi-parametric model, without the complexity of a full
local fit. Under the context of the dataset, we can easily divide the three 
predictor variables into two disjoint groups, one includes longitude and latitude
which is the horizontal direction, and another is elevation in the vertical 
direction. It is a well known fact that the pressure is decreasing when altitude
is going up. Therefore at a given location, the temperature is decreasing as well
when altitude is high. It is plausible to specify the maximum temperature to be
conditionally parametric in longitude and latitude.
Making such a specification when it is valid can result in a more parsimonious fit.
An exceedingly simple modification of loess fitting yields a conditionally
parametric surface. We simply ignore the elevation factor in computing the 
distances that are used in the definition of the neighborhood weights, $W_i$(x).

Let us demonstrate the concept and implementation with more details. The method 
for making a loess fit conditionally parametric in a proper subset of predictors 
is simple. The subset is ignored in computing the distances that are used in the 
definition of the neighborhood weights, $\omega_i(x)$.
Suppose that there are two predictors in order to make the point straight forward, 
$\mu$ and $\nu$. Suppose we specify $\mu$ to be the global variable of the 
conditionally parametric model. Since the weight function ignores the variable 
$\mu$ the $i$th weight, 
$\omega_i(\mu, \nu)$ for the fit at $(\mu, \nu)$, is the same as the $i$th weight, 
$\omega_i(\mu+\delta, \nu)$, for the fit at $(\mu+\delta, \nu)$. Thus the quadratic 
polynomial that is fitted locally for the fit at $(\mu, \nu)$ is the same as the 
quadratic polynomial that is fitted locally for the fit at $(\mu+\delta, \nu)$, 
whatever the value of $\delta$. So for the fixed 
value of $\nu$, the surface is exactly this quadratic as a function of the $\mu$.

A growing list of practical applications has shown that conditionally parametric
fits add structure in a way that is quite useful in practice 
\cite{cleveland1991computational} and \cite{hastie1990generalized}. In 
\cite{cleveland1994coplots}, Cleveland illustrate the conditional parametric model
using Taylor series approximations as a handrail, which is very delightful.
Specifically, consider the maximum temperature surface as a function over all 
factor longitude, latitude, and elevation. And suppose the surface is very complex
and has a lot of peaks and valleys. By Taylor series, if the elevation is varied 
by a sufficiently small amount, the temperature surface can be well approximated
by a very simple function, linear or quadratic given the value of longitude and
latitude. In \cite{cleveland1992local}, The conditionally parametric model is 
compared to the partially linear model, which is similar with it. However, the 
conditionally parametric model allows all coefficients of the parametric variables 
to depend on the smoothing variables, which is not valid in partially linear
model. 

\subsubsection{span=0.015, degree=2}

Based on the result we found in the section~\ref{sec:impute.w/o.elev}, we modify 
the span of spatial spatial smoothing to be 0.015, which means about 75 stations 
in the neighborhood of the target location will be used for local weighted 
regression fit if there are roughly 5,000 locations in total. The degree for 
longitude and latitude variables are kept as quadratic, and the degree for 
conditional parameter elevation is also specified as quadratic. We demonstrate 
and assess the spatial smoothing result for this fit in the following diagnostics 
graph.

Similarly, the quantiles between 0.015 and 0.095 of spatial smoothing residual is 
plotted against to the corresponding quantiles from a unit Normal distribution in 
Figure
\href{../plots/a1950/spaimpute/elev/d2/span0.015/a1950.spaResidcenter.bytime.pdf}
{\ref*{elev2.0.015.Residcenter.bytime}}. As we can notice, even though the 
distribution of residual still has a longer tail than unit Normal distribution,
the range of it for each month is about from -2 to 2 collectively, which is about 
60 percent less of the range of residual in the previous spatial smoothing model. 
Also the longer tail issue becomes less severe than previous one.

\begin{framed}
\begin{center}
  \href{../plots/a1950/spaimpute/elev/d2/span0.015/a1950.spaResidcenter.bytime.pdf}
  {Link to figure}
  \captionof{figure}
  {The normal quantiles between 0.015 and 0.985 of residual of spatial spatial 
  smoothing}
  \label{elev2.0.015.Residcenter.bytime}
\end{center}
\end{framed}

Next, we generate the diagnostics plots about the residual against to one of the 
predictor variables to detect any pattern left in the residual with respect to
the predictors. As shown in Figure
\href{../plots/a1950/spaimpute/elev/d2/span0.015/a1950.spaResid.vs.lat.lon.pdf}
{\ref*{elev.0.015.Residvslat.lon}}, spatial smoothing residual is drawn against 
to latitude conditional on longitude. Again, longitude is equally cut into 20 
intervals, and a loess smoothing curve with span equal to 0.25 and degree 1 is
added, which is approximately a flat horizontal line around 0. Furthermore, 
compared with Figure 
\href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResid.vs.lat.lon.pdf}
{\ref*{nonelev.0.05.Residvslat.lon}}, which does not include elevation as a
conditional parameter, the outlier issue in the first five panels are not as 
severe as it in Figure 
\href{../plots/a1950/spaimpute/nonelev/span0.05/a1950.spaResid.vs.lat.lon.pdf}
{\ref*{nonelev.0.05.Residvslat.lon}}, or even disappeared in some of months.
Besides that, the station \texttt{275639} with elevation 1909 meters, longitude 
-71.30 degree and altitude 44.27 degree in the last panel is not an outlier 
anymore.

\begin{framed}
\begin{center}
  \href{../plots/a1950/spaimpute/elev/d2/span0.015/a1950.spaResid.vs.lat.lon.pdf}
  {Link to figure}
  \captionof{figure}
  {The residual of spatial spatial smoothing against to latitude conditional on 
  longitude}
  \label{elev.0.015.Residvslat.lon}
\end{center}
\end{framed}

Then, We switch longitude and latitude, and plot the residuals against to longitude
conditional on 20 intervals of latitude. Still most of the outliers existed in 
the previous spatial smoothing in section~\ref{sec:impute.w/o.elev} are vanished 
across all panels in Figure
\href{../plots/a1950/spaimpute/elev/d2/span0.015/a1950.spaResid.vs.lon.lat.pdf}
{\ref*{elev.0.015.Residvslon.lat}}. Same for the outliers in the region of 
Appalachian Mountains. Consequently, we keep the result of current fitting, span 
equal to 0.015 and degree equal to 2, to only impute the missing values in the 
original dataset.

\begin{framed}
\begin{center}
  \href{../plots/a1950/spaimpute/elev/d2/span0.015/a1950.spaResid.vs.lon.lat.pdf}
  {Link to figure}
  \captionof{figure}
  {The residual of spatial spatial smoothing against to longitude conditional on 
  latitude}
  \label{elev.0.015.Residvslon.lat}
\end{center}
\end{framed}

Of course, we are not trying to perfectly capture the spatial variation in the
maximum temperature within this spatial smoothing. It is only to fill in the 
missing values and smooth out some spatial noise, which will be a rigorous 
problem in \texttt{stlplus} fit in the next section. Another crucial reason for
smoothing spatially first is for the prediction at a new location. Suppose we 
would like to carry out prediction at a new location where there is no historical 
data at all. So all information we can borrow for predicting is based on spatial 
dimension instead of time dimension. We smooth by assuming there is only very 
limited relation between different locations in two different months. After the 
spatial smoothing at the new location for each month in parallel, we then will 
carry out the fitting in time dimension as demonstrated in the following section 
since we generated an estimated time series at the new location.

