%
%  revised  front.tex  2011-09-02  Mark Senn  http://engineering.purdue.edu/~mark
%  created  front.tex  2003-06-02  Mark Senn  http://engineering.purdue.edu/~mark
%
%  This is ``front matter'' for the thesis.
%
%  Regarding ``References'' below:
%      KEY    MEANING
%      PU     ``A Manual for the Preparation of Graduate Theses'',
%             The Graduate School, Purdue University, 1996.
%      TCMOS  The Chicago Manual of Style, Edition 14.
%      WNNCD  Webster's Ninth New Collegiate Dictionary.
%
%  Lines marked with "%%" may need to be changed.
%

% Dedication page is optional.
% A name and often a message in tribute to a person or cause.
% References: PU 15, WNNCD 332.
\begin{dedication}
  To my wife and my parents. I couldn't have done this without you.
\end{dedication}

% Acknowledgements page is optional but most theses include
% a brief statement of apreciation or recognition of special
% assistance.
% Reference: PU 16.
\begin{acknowledgments}

No one denies that finishing a PhD degree is a long and difficult journey. And I 
could not have done it without the help and support of a lot of people.

First of all I would like to express my deeply appreciation and thank to my 
advisor Dr. William S. Cleveland. I really treasured this rare opportunity to 
work with such an outstanding professor. Dr. Cleveland guided me with his unique 
thinking, needs for perfect in details of the visualization, and his enthusiasm 
to research, which indeed profoundly influenced me and will keep influencing and
benefiting me in my future career.

At the same time, I really like to thank the other committee members, Dr. Anindya 
Bhadra, Dr.Ryan Hafen, Dr.Hao Zhang, and Dr.Boyu Zhang. Thank you all for your 
valuable suggestion and unselfish support and help to me during this journey.

Also I would like to give a special thank you to Dr.Mark Daniel Ward, Dr.Sergey
Kirshner, Douglas G. Crabill, and Dr.Rebecca Doerge. Dr.Ward I really do not how 
to express my thank to you for helping me preparing the Qualify Exams and my 
wedding. That morning in the kitchen of your house discussing probability questions 
with you was a very special and unforgettable moment in my life. You are an 
wonderful professor. Dr.Sergey Kirshner thank you for leading me to the world of 
Computational Statistics in the class of STAT598G. Those sleepless night doing 
project really profoundly stimulated my interests to be a PhD student in the area 
of computational statistics. Doug, I can barely count how many times I have been
sitting in your office. Thank you for tutoring me with all basic 
knowledge about Hadoop and cluster. And thank you for your time and patience to 
help me with my projects. Sincere thanks to Dr.Rebecca Doerge for all the support 
and encouragement during this six years. You taught me a lot of thing which made 
me to be a better man.

I want to say thank you to all my former and present colleagues, Jianfu, Xiang, 
Jiasen, Ashrith, Philip, Aritra, Yuying, Qi, Barret, Jeremy. Jianfu, thank you 
very much for your patience when you unreservedly passed on to me your 
understanding about Hadoop and RHIPE, I cannot be expert on this without your 
teaching. Barret thank you for all your technical support and unselfish help to 
me whenever I said "May I ask you a question" to you. And I miss the time playing
pingpong with Philip at Purdue and at Amazon as well, I lost a lot of games though.

I also want to thank all my dear friends at Purdue. Because of you, this journey
becomes shorter according to the theory of relativity. Cheng Liu, thank you for 
being my mentor since the first day I came to Purdue; Cheng and Ximing, thank you 
for all the fun and hangover we have had as roommates in the Lodge; Qiming, thank 
you for your patience and time to help me preparing the talk I gave in the Amazon, 
and all the happy hours we shared during our internship over there in that summer,
and I am looking forward to our new life in Seattle; Pan, thank you for sharing 
your knowledge and experience when we were doing project about Scala and Spark; 
Yang, Longjie, Xiaoguang, Hanli, Zhuo, Shuai, Faye, April, Kelly-Ann, thank you 
for being such great classmates during all the classes we had before; this list 
keeps going on, and I thank you all for the happiness you bring to me.

I am very pleased to have an opportunity to spend the last six years in the 
Department of Statistics at Purdue. The department provides an excellent 
environment and various opportunities. I have learned so much from many faculty 
and stuff members, as well as our excellent graduate students.

Finally, I want to thank my parents, and my beloved wife, Fang Fang, for all 
their patience, encouragement, and unconditional love, thank you so much.

\end{acknowledgments}

% The preface is optional.
% References: PU 16, TCMOS 1.49, WNNCD 927.
%\begin{preface}
%  This is the preface.
%\end{preface}

% The Table of Contents is required.
% The Table of Contents will be automatically created for you
% using information you supply in
%     \chapter
%     \section
%     \subsection
%     \subsubsection
% commands.
% Reference: PU 16.
\tableofcontents

% If your thesis has tables, a list of tables is required.
% The List of Tables will be automatically created for you using
% information you supply in
%     \begin{table} ... \end{table}
% environments.
% Reference: PU 16.
%\listoftables

% If your thesis has figures, a list of figures is required.
% The List of Figures will be automatically created for you using
% information you supply in
%     \begin{figure} ... \end{figure}
% environments.
% Reference: PU 16.
\listoffigures

% List of Symbols is optional.
% Reference: PU 17.
\begin{symbols}
  $x_0$& target fitting point\cr
  $x_i$& design points\cr
  $y_i$& response variable\cr
  $\omega_i$& weights\cr
  $w$& smoothing window size in STL\cr
  $w_s$& smoothing window size for trend seasonal smoothing\cr
  $t_i$& trend component\cr
  $s_i$& seasonal component\cr
  $r_i$& remainder\cr
  $n_{(I)}$& iteration time of inner loop\cr
  $k$& iteration index\cr
\end{symbols}

% List of Abbreviations is optional.
% Reference: PU 17.
\begin{abbreviations}
  COOP& Cooperative Observer Program\cr
  D\&R& Divide-and-Recombine\cr
  GB& Gigabyte\cr
  GWR& Geographically Weighted Regression\cr
  HDFS& Hadoop Distributed File System\cr
  IBP& mapreduce.reduce.input.buffer.percent\cr
  IMAGe& Institute of Mathematics Applied to Geosciences\cr
  ISF& mapreduce.task.io.sort.factor\cr
  ISM& mapreduce.task.io.sort.mb\cr
  JVM& Java Virtual Machine\cr
  KB& Kilobyte\cr 
  MAPE& Mean of Absolute value of Prediction Error\cr
  MB& Megabyte\cr
  MRCC& Midwestern Regional Climate Center\cr
  MSDPE& Mean of Standard Deviation of Prediction Error\cr
  NCDC& National Climatic Data Center\cr
  NCEI& National Centers for Environmental Information\cr
  NW& Nadaraya-Watson\cr
  NRCS& Natural Resources Conservation Service\cr
  NWS& National Weather Service\cr
  RHIPE& R and Hadoop Integrated Programming Environment\cr
  RTSK& mapreduce.job.reduces\cr
  RSC& mapreduce.job.reduce.slowstart.completedmaps\cr
  SDPE& Standard Deviation of Prediction Error\cr
  SSP& mapreduce.map.sort.spill.percent\cr
  SPC& mapreduce.reduce.shuffle.parallelcopies\cr
  SIBP& mapreduce.reduce.shuffle.input.buffer.percent\cr
  SMP& mapreduce.reduce.shuffle.merge.percent\cr
  SNOTEL& Snowpack telemetry\cr
  STL& Seasonal Trend Loess\cr
  USDA& United States Department of Agriculture\cr
  USHCN& United States Historical Climatology Network\cr

\end{abbreviations}

% Nomenclature is optional.
% Reference: PU 17.
%\begin{nomenclature}
%  Alanine& 2-Aminopropanoic acid\cr
%  Valine& 2-Amino-3-methylbutanoic acid\cr
%\end{nomenclature}

% Glossary is optional
% Reference: PU 17.
%\begin{glossary}
%  chick& female, usually young\cr
%  dude& male, usually young\cr
%\end{glossary}

% Abstract is required.
% Note that the information for the first paragraph of the output
% doesn't need to be input here...it is put in automatically from
% information you supplied earlier using \title, \author, \degree,
% and \majorprof.
% Reference: PU 17.
\begin{abstract}
In the first chapter of this thesis, I briefly introduce one type of nonparametric
regression method, namely local polynomial regression method, followed by emphasis 
on two specific generalizations of loess, which are time series decomposition 
method called Seasonal Trend Loess (STL) and Geographically weighted Regression. 
The main purpose here is to cover the foundation methodology and principle of the 
data analysis in later chapter, which crucially depends on these topics. The 
chapter is closed by the introduction of D\&R (Divide and Recombined)
statistical framework. Data can be divided into subsets, each of which is applied
with a statistical analysis method. This is an embarrassing parallel procedure
since there is no communication between each subset. Then the analysis result for
each subset are combined together to be the final analysis outcome for the whole
dataset.

In the second chapter, I utilize spatial loess and STL methods under the divide 
and recombined framework to analyze a spatial-temporal data, which is about the 
monthly average of daily temperature for the contiguous United States from 
January 1895 to December 1997. A statistical analysis routine, which consists of 
a series of MapReduce jobs, is applied to the spatial-temporal dataset. First 
conditionally parametric spatial loess method is introduced and applied to the 
by-month division of the dataset. Elevation is considered as global parameter in 
the model. Next, the by-station division containing the spatial smoothing value
is generated by a MapReduce job and then passed into another MapReduce job to 
carry out the Seasonal Trend Loess (STL) fitting in each station in parallel. 
An experiment of tunning smoothing parameters of STL is explored based on 
data after year 1950 to choose the best smoothing parameters in terms of 
prediction ability. For each station, 270 observations are treated as training 
data to prediction the oncoming 36 observations. This procedure is repeated by 
moving the time period of training data one month ahead until the last observation 
is predicted. 

In the third chapter, I present an analysis of the performance of the analysis 
method I proposed in previous chapter for a large spatial temporal data. The
performance of MapReduce jobs in the analysis routine can be effected by several
factors. The factors I consider in the thesis are those user-tunable MapReduce 
tunning parameters. The elapsed times for those MapReduce jobs are measured as 
the response variable which represents the performance of the routine. A full 
factorial experiment with three replicates is conducted to study the affect of 
these tunning parameters to the performance of analysis routine.
\end{abstract}
