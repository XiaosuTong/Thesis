\section{Exploratory Analysis}

The FTP distribution for the 103-year monthly maximum temperature data set along
with supporting meta-data can be found at \cite{data}. 
However, the data set not only includes the raw observed monthly
maximum temperature, but also infills all missing values by statistical infilled
method conducted by IMAGe. 
When using the complete data for further statistical analysis care should be taken
with the infilled values. Although they are good estimates of the mean they may 
not reproduce the variability that one would expect from actual point 
observations of the meteorology. In statistical language, the infilled values are
the mean of the conditional distribution for the measurement given the observed 
data. They are not samples from this conditional distribution. 
So we eliminate all infilled values from our data analysis.

In this section, we describe the procedures of our data downloading and initial 
processing, followed by summary statistics of the observed monthly maximum 
temperature. Further processing of the data into multiple databases of various 
structures are discussed in details in the following sections along with the 
corresponding analyses enabled and facilitated by each database.

\subsection{Data Download and Initial Database}
\label{sec:Download}

The raw data set is in fixed width text format with 103 files having file names in
the form: 
\texttt{tmax.complete.Ynnn} with \texttt{nnn = 001, 002,} $\cdots$\texttt{, 103} 
which \texttt{001 = 1895} and \texttt{103 = 1997}. Each separate data file consists
of the maximum temperature for a single year. Each line of the file contains 12
monthly maximum temperature observations and 12 observed/missing value codes 
(\texttt{1=missing}, \texttt{0=observed}). We only keep the observed monthly
maximum temperature in our analysis. Totally there are 8,125 stations in each file,
and temperature appears as a integer in tenths of Celsius degree. For instance, 73
in the raw text file should be interpreted as 7.3 Celsius degrees. 

Additionally, besides the 103 raw data files, there is metadata about stations' 
information which includes:
\begin{enumerate}
  \item The station id, which uniquely identifies each station.
  \item The degree of longitude of station.
  \item The degree of latitude of station.
  \item The meter of elevation of station.
\end{enumerate}
The metadata set is in text format of 244 KB.

The first step of our 
data downloading is to parallelly download 103 data files from IMAGe data base and 
transferred from the local file system of the cluster to the HDFS. This is done
through a MapReduce job described as follow.
\begin{description}
  \item[Input] Integers from 1 to 103. There is no real input files feed into this
  MapReduce job. Instead, we simulate the key of input key-value pairs to be
  sequence of integer from 1 to 103 which is exactly the number of data set files. 
  Each of them is passed to one Mapper. 
  \item[Output] The same text files on HDFS.
  \item[Map] Download one file in each mapper. For each Mapper, the download link
  is generated by concatenating the string\\
  \texttt{https://www.image.ucar.edu/pub/nychka/NCAR\_tinfill/tmax.complete.Y}
  with the integer passed into this Mapper. The corresponding data file is
  downloaded into a temporal directory on the local file system of the server on 
  which the Mapper is running, and then this local copy of file is copied 
  into HDFS after Map is finished.  
  \item[Reduce] Reduce is not needed in this MapReduce job.
\end{description}
The total raw text files saved on HDFS are around 90MB. Totally there are 836,875 
lines in text files, and each line of the raw text file corresponded to twelve
monthly maximum temperature observations for a given station in a given year
followed by their status code of observation (observed or missing) in terms of 0/1.

\subsubsection{Construction of the Initial Database}

Next, an initial database of the whole data set is created based on plain text
files. We consider to transform the raw text files to be a more
analysis friendly structure, which only has one observation per row. Concretely,
the new structure should include following fields (columns) for each observation.
We use \texttt{NA} to represent missing value of the maximum temperature for a
given month:

\begin{enumerate}
  \item The station ID, which uniquely identifies each station.
  \item The degree of longitude of the station.
  \item The degree of latitude of the station.
  \item The meter of elevation of the station.
  \item The station name.
  \item The year of the observation.
  \item The month of the observation.
  \item The observation of the maximum temperature for the given month.
\end{enumerate}

By utilizing the RHIPE, which bridges the R and Hadoop, the new data structure can
be easily achieved within one MapReduce job by specifying RHIPE commands in R.
Moreover, each observation is saved in terms of R object, specifically a data.frame
with only one row and eight columns.
We make the choice of R data.frame because it allows us to have different type of
class for each column, and also it is extremely friendly to a great many of
statistical analysis functions in R. 

The observation database is fulfilled in a MapReduce job described as
below:

\begin{description}
  \item[Input] 103 plain text files saved on HDFS, each of which consists of 8,125 
  lines. Each line includes information about 12 months maximum temperature for a 
  given station in a given year. The year information can be pulled from last three
  characters of the name of each text file, which \texttt{001 = 1895} and 
  \texttt{103 = 1997}. Lines contain 14 tab-delimited columns:
  (1) the station id, (2) to (13) the monthly maximum temperature from January to
  December, (14) a 12-digit character which indicates if 12 monthly maximum 
  temperature is observed or missing. 
  \item[Output] 10,042,500 observations, each of which is a key-value pair, with 
  8,125 unique station ID and 1,236 month index together as the key, and a one-row 
  R data.frame as value, which includes (1) 
  \texttt{station name}, the name of station, (2) \texttt{longitude}, degree of 
  longitude of the station, (3) \texttt{latitude}, the latitude of the station, (4)
  \texttt{elevation}, the meter of elevation the station, (5) \texttt{year}, year 
  of the observation, (6) \texttt{month}, month of year (January to December), 
  (7) \texttt{tmax}, the monthly maximum temperature
  \item[Map] Parse each line of the text file as a character string. For each line,
  we split the character string based on separator \texttt{\textbackslash t} by 
  calling R function \texttt{strsplit}, and then the station ID in the first field 
  is extracted out, and with the month index together are used as the key of the 
  intermediate key-value pairs. The rest of fields are saved in a R one-row 
  data.frame as the value of the intermediate key-value pairs. The intermediate 
  key-value pairs are transferred to Reduce. 
  \item[Reduce] Identity reduce function do not do anything to the intermediate 
  key-value pairs besides evenly distributes all intermediate key-value pairs to 
  multiple files, and save them on HDFS.
\end{description}

\subsection{Summary of the Data}
\label{sec:summaryData}

In summary, the dataset covers monthly maximum temperature over the period of 103
years, from Jan 1895 to Dec 1997. 8,125 stations are scattered across the 
conterminous US excluding Hawaii and Alaska. Concretely, the elevation of 
stations ranges from -59 to 3801 meters, the longitude ranges from -124.73 degree
to -67 degree, and the latitude ranges from 24.55 degree to 49 degree. 

\subsubsection{Location of Stations}

Figure \href{../plots/allstationsone.pdf}{\ref*{all.location}} illustrates the
location of all stations on the map of United States.

\begin{framed}
\begin{center}
  \href{../plots/allstationsone.pdf}{Link to figure}
  \captionof{figure}{The location of all stations}
  \label{all.location}
\end{center}
\end{framed}

Meanwhile, we equally split the stations into 8 groups based on their elevation, 
which cutting points are at 58m, 162m, 244m, 351m, 581m, 1098m, and 1647m. And 
then location of stations are demonstrated on map of United States conditional on 
the elevation.

\begin{framed}
\begin{center}
  \href{../plots/allstations.pdf}{Link to figure}
  \captionof{figure}{The location of stations conditional on elevation}
  \label{all.location.multi}
\end{center}
\end{framed}

Besides the demonstration of stations based on longitude and latitude, the 
distribution of elevation of each station is also shown in Figure 
\href{../plots/QQelevation.pdf}{\ref*{QQelevation}}.

\begin{framed}
\begin{center}
  \href{../plots/QQelevation.pdf}{Link to figure}
  \captionof{figure}{Quantiles of elevation of stations}
  \label{QQelevation}
\end{center}
\end{framed}

In Figure \href{../plots/QQelevation.pdf}{\ref*{QQelevation}}, horizontal dash 
lines are the cutting points of elevation when we split stations into groups. 
It shows that more than
60\% of stations are below 581 meters. Figure 
\href{../plots/allstations.pdf}{\ref*{all.location.multi}} tells us that those 
stations are mainly outside of the 
Pacific Coast Ranges (officially gazetted as the Pacific Mountain System in the 
United States), which includes the Rocky Mountains, Columbia Mountains, Interior
Mountains, the Interior Plateau, Sierra Nevada Mountains, the Great Basin mountain 
ranges. Also, there are 724 station are on the west coast of United States, which
is between the Pacific Ocean and the Pacific Coast Ranges.

\subsubsection{The Number of Observation}

As we mentioned in section~\ref{sec:Download}, missing values has been saved as 
\texttt{NA} in the database. We would like to reveal where and when those 
missing values turn up.
In Figure \href{../plots/obs_month.pdf}{\ref*{obs.month}}, the log base 2 number
of observation is drawn against date. The red solid reference line in the plot is 
the $\log_2(8125)$, which is the number of observation when there is no missing 
value in that given month. The number of observation increased gradually from Jan
1895 to Jan 1915. But then there was a dramatically jump in 1931. The valid
observation number arose from 1,619 on Dec 1930 to 2,953 on Jan 1931. After Jan 
1950, the count of observation stayed around $5,000$, which is 65\% of all
stations. 

\begin{framed}
\begin{center}
  \href{../plots/obs_month.pdf}{Link to figure}
  \captionof{figure}{The number of observations over time}
  \label{obs.month}
\end{center}
\end{framed}

With a deeper look into the database, we found January has minimum number of 
observation in 70 out of 103 years. So the observation count is plotted against
date superposed on month of year, only for January, February, and December in 
Figure \href{../plots/obs_month_byseason.pdf}{\ref*{obs.month.season}}

\begin{framed}
\begin{center}
  \href{../plots/obs_month_byseason.pdf}{Link to figure}
  \captionof{figure}{The number of observations around Jan 1982}
  \label{obs.month.season}
\end{center}
\end{framed}

There is not huge difference between 12 month of year with respect to the 
observation count before 1981. However, Figure 
\href{../plots/obs_month.pdf}{\ref*{obs.month}} and 
Figure \href{../plots/obs_month_byseason.pdf}{\ref*{obs.month.season}} both 
indicate there is a significant drop of observation count on Jan 1982. And among 
the 16 years after that, January always has the lowest observation count.

Moreover, we found that this drop on Jan 1982 is not caused by adjustment of 
the stations such as one station shift its location to its neighborhood. It is
because the 688 stations got missing observation on Jan 1982, but then they
went back to be active again on Feb 1982, as shown in Figure 
\href{../plots/obs_Jan1982.pdf}{\ref*{Jan1982}}. The blue circles represent 
stations whose observation status were changed to be missing from December 1981
to January 1982. Meanwhile the magenta solid points represent stations whose
observation status shifted back to be valid from January 1982 to February 1982.
If a location has both blue circle and magenta solid point, it means that location
of weather station suddenly was failing on January 1982 but then went back on
February 1982. 

\begin{framed}
\begin{center}
  \href{../plots/obs_Jan1982.pdf}{Link to figure}
  \captionof{figure}{The location of active stations around Jan 1982}
  \label{Jan1982}
\end{center}
\end{framed}

We believe this astonishing number of failure of stations on January 1982 is caused
by severe weather on January 1982, which may cause the battery in the weather 
station died. As shown in Figure \href{../plots/monthmean.pdf}{\ref*{min.monthmean}},
the mean of monthly minimum temperature over all stations are plotted against 
date from 1931 to 1998. We found on January 1982, it reached the minimum value 
of $-15.65$. And this is only for stations who has record in that month, there 
were a lot of stations had missing value may have even lower records.  
From January 11 to January 17, A brutal cold snap sends temperatures to all-time 
record lows in dozens of cities throughout the Midwestern United States. Especially
on January 17, 1982, so called "Cold Sunday"\cite{coldsunday}, in numerous cities 
temperatures fall to their lowest levels in over 100 years.

\begin{framed}
\begin{center}
  \href{../plots/monthmean.pdf}{Link to figure}
  \captionof{figure}{The monthly minimum temperature vs. date}
  \label{min.monthmean}
\end{center}
\end{framed}
