\section{Exploratory Analysis}

The FTP distribution of the 103-year monthly maximum temperature data set along
with supporting meta-data can be found at the web page \cite{data}. 
However, the data set not only includes the raw observed monthly
maximum temperature, but also has in-filled missing values which are calculated 
by statistical in-filled method proposed by IMAGe \cite{data}. Since those 
in-filled values are not samples from the underlining  conditional distribution
of response variable, we eliminate all in-filled values from our data analysis. 
So missing value is a problem we will also tackle in our analysis.

In this section, we describe the procedures of our data downloading and initial 
processing, followed by summary statistics of the observed monthly maximum 
temperature. Further processing of the data into multiple databases of various 
structures are discussed in details in the following sections along with the 
corresponding analyses enabled and facilitated by each database.

\subsection{Data Download and Initial Database}
\label{sec:Download}

The raw dataset is in fixed-width text format with 103 files having file names 
in the form of \texttt{tmax.complete.Ynnn} with \texttt{nnn = 001, 002,} $\cdots$
\texttt{, 103} which \texttt{001 = 1895} and \texttt{103 = 1997}. Each separate 
data file consists of the maximum temperature for a single year. Each line of the 
file contains 12 monthly maximum temperature observations and 12 observed/missing 
value codes (\texttt{1=missing}, \texttt{0=observed}). We only keep the observed 
monthly maximum temperature in our analysis, and use \texttt{NA} to represent
those missing value. Totally there are 8,125 stations in each file, and 
temperature appears as a integer in tenths of Celsius degree. For instance, 73 
in the raw text file should be interpreted as 7.3 degrees Celsius. 

Additionally, besides the 103 raw data files, there is metadata about stations' 
information which includes:
\begin{enumerate}
  \item The station id, which uniquely identifies each station.
  \item The degree of longitude of station.
  \item The degree of latitude of station.
  \item The meter of elevation of station.
\end{enumerate}
The metadata set is in text format of 244 KB.

The first step is to parallelly download 103 data files from IMAGe data base and 
save to the HDFS on the cluster. This is done through a MapReduce job described 
as follows. Within the entire thesis, map task and mapper can be treated as 
equivalent. Same for the reduce task
and reducer.
\begin{description}
  \item[Input] Integers from 1 to 103. There is no real input files fed into this
  MapReduce job. Instead, we simulate the key of input key-value pairs to be
  sequence of integer from 1 to 103, which is exactly the number of data set files. 
  Each of them is passed to one Mapper. 
  \item[Output] The 103 text files saved on HDFS.
  \item[Map] Download one file in each mapper. For each Mapper, the download link
  is generated by concatenating the string\\
  \texttt{https://www.image.ucar.edu/pub/nychka/NCAR\_tinfill/tmax.complete.Y}
  with the integer passed into this Mapper. The corresponding data file is
  downloaded into a temporal directory on the local file system of the server on 
  which the Mapper is running, and then this local copy of the file is automatically 
  copied onto HDFS after Map is finished.  
  \item[Reduce] Reduce is not needed in this MapReduce job.
\end{description}
The total raw text files saved on HDFS are around 90MB. Totally there are 836,875 
lines in text files. Each line of the raw text file corresponded to twelve
monthly maximum temperature observations for a given station in a given year
followed by their status code of observation (observed or missing) in terms of 0/1.

\subsubsection{Construction of the Initial Database}

Next, an initial database of the whole data set is created based on plain text
files. We consider to transform the raw text files to be a more
analysis friendly structure, which only has one monthly observation per row. 
Concretely, the new structure should include following fields (columns), and we 
use \texttt{NA} to represent missing value in the \texttt{tmax} column:

\begin{enumerate}
  \item \texttt{station.id}, the station ID, which uniquely identifies each 
  station.
  \item \texttt{lon}, the degree of longitude of the station.
  \item \texttt{lat}, the degree of latitude of the station.
  \item \texttt{elev}, the meter of elevation of the station.
  \item \texttt{year}, the year of the observation.
  \item \texttt{month}, the month of the observation.
  \item \texttt{tmax}, the observation of the maximum temperature for the given 
  month.
\end{enumerate}

By utilizing the RHIPE, which bridges the R and Hadoop, the new data structure 
can be easily achieved within one MapReduce job by specifying RHIPE commands in 
R. Moreover, the value of each key-value pair generated is saved in terms of R 
object, specifically a data.frame with only one row and eight columns.
We make the choice of R data.frame because it allows us to have different type of
class for each column, and also it is extremely friendly to a great many of
statistical analysis functions in R. A more critical reason for generating this
initial database is that it provides more flexibility of producing different
division of the dataset from the initial database, such as by-month or by-station
division which we will discuss with more details in the next several sections. 
It also generalizes our analysis procedure to be feasible to different types of
spatial-temporal dataset. 

Before generating the initial database on HDFS, the metadata about station 
information is processed to be a R data.frame object and saved on HDFS as 
RData file, \texttt{statinfo.RData} in advance.
The initial database is fulfilled in a MapReduce job described as below:

\begin{description}
  \item[Input] 103 plain text files saved on HDFS, each of which consists of 8,125 
  lines. Each line includes information about 12 months maximum temperature for a 
  given station in a given year. The year information can be pulled from last three
  characters of the name of each text file, which \texttt{001 = 1895} and 
  \texttt{103 = 1997}. Lines contain 14 tab-delimited columns.
  \item[Output] 10,042,500 observations, each of which is a key-value pair, with 
  a combination of 8,125 unique station ID and 1,236 month index \texttt{date} as 
  the key, and a one-row R data.frame as value, which includes (1) \texttt{lon}, 
  degree of longitude of the station, (2) \texttt{lat}, the latitude of the station, 
  (3) \texttt{elev}, the meter of elevation the station, (4) \texttt{year}, 
  year of the observation, (5) \texttt{month}, month of year (January to December), 
  (6) \texttt{tmax}, the monthly maximum temperature
  \item[Map] The shared RData file containing all location information is copied 
  and loaded into the global environment of R session in each mapper. Meanwhile,
  Parse each line of the text file as a character string. For each line,
  we split the character string based on separator \texttt{\textbackslash t} by 
  calling R function \texttt{strsplit}, and then the station ID in the first field 
  is extracted out, and with the month index together are used as the key of the 
  intermediate key-value pairs. The rest of fields with the station information
  matched by station ID, are saved in a R one-row data.frame as the value of the
  intermediate key-value pairs. 
  \item[Reduce] The identity reduce function do not do anything to the 
  intermediate key-value pairs besides evenly distributing all intermediate 
  key-value pairs to multiple files, and save them on HDFS.
\end{description}

\subsection{Summary of the Data}
\label{sec:summaryData}

In summary, the dataset covers monthly maximum temperature over the period of 103
years, from Jan 1895 to Dec 1997. 8,125 stations are scattered across the 
conterminous US excluding Hawaii and Alaska. Concretely, the elevation of 
stations ranges from -59 to 3801 meters, the longitude ranges from -124.73 degree
to -67 degree, and the latitude ranges from 24.55 degree to 49 degree. 

\subsubsection{Location of Stations}

Figure \href{../plots/allstationsone.pdf}{\ref*{all.location}} illustrates the
location of all 8,125 stations on a map of United States.

\begin{framed}
\begin{center}
  \href{../plots/allstationsone.pdf}{Link to figure}
  \captionof{figure}{The location of all stations}
  \label{all.location}
\end{center}
\end{framed}

Meanwhile, we equally split the stations into 8 groups based on their elevation. 
Cutting points are at 58m, 162m, 244m, 351m, 581m, 1098m, and 1647m. And 
then location of stations are demonstrated on a map of United States conditional 
on the elevation.

\begin{framed}
\begin{center}
  \href{../plots/allstations.pdf}{Link to figure}
  \captionof{figure}{The location of stations conditional on elevation}
  \label{all.location.multi}
\end{center}
\end{framed}

Besides the demonstration of stations based on longitude and latitude, the 
distribution of elevation of each station is also shown in Figure 
\href{../plots/QQelevation.pdf}{\ref*{QQelevation}}.

\begin{framed}
\begin{center}
  \href{../plots/QQelevation.pdf}{Link to figure}
  \captionof{figure}{Quantiles of elevation of stations}
  \label{QQelevation}
\end{center}
\end{framed}

In Figure \href{../plots/QQelevation.pdf}{\ref*{QQelevation}}, horizontal dash 
lines are the cutting points of elevation when we split stations into groups. 
It shows that more than
60\% of stations are below 581 meters. Figure 
\href{../plots/allstations.pdf}{\ref*{all.location.multi}} tells us that those 
stations are mainly outside of the 
Pacific Coast Ranges, which includes the Rocky Mountains, Columbia Mountains, 
Interior Mountains, the Interior Plateau, Sierra Nevada Mountains, the Great 
Basin mountain ranges. Also, there are 724 stations are on the west coast of 
United States, which is between the Pacific Ocean and the Pacific Coast Ranges.


\subsubsection{The Number of Observation}

As we mentioned in section~\ref{sec:Download}, missing values have been saved as 
\texttt{NA} in the database. We would like to reveal where and when those 
missing values turn up.
In Figure \href{../plots/obs_month.pdf}{\ref*{obs.month}}, the log base 2 number
of observation is drawn against date. The red solid reference line in the plot is 
the $\log_2(8125)$, which is the number of observation when there is no missing 
value in that given month. The number of observations increased gradually from 
Jan 1895 to Jan 1915. But then there was a dramatically jump in 1931. The valid
observation number arose from 1,619 on Dec 1930 to 2,953 on Jan 1931. After Jan 
1950, the count of observation stayed around $5,000$, which is 65\% of all
stations. 

\begin{framed}
\begin{center}
  \href{../plots/obs_month.pdf}{Link to figure}
  \captionof{figure}{The number of observations over time}
  \label{obs.month}
\end{center}
\end{framed}

A deeper look into the database shows that January has minimum number of 
observation in 70 out of 103 years. So the observation count is plotted against
date superposed on month of year, only for January, February, and December in 
Figure \href{../plots/obs_month_byseason.pdf}{\ref*{obs.month.season}}

\begin{framed}
\begin{center}
  \href{../plots/obs_month_byseason.pdf}{Link to figure}
  \captionof{figure}{The number of observations around Jan 1982}
  \label{obs.month.season}
\end{center}
\end{framed}

There is not huge difference between 12 month of year with respect to the 
observation count before 1981. However, Figure 
\href{../plots/obs_month.pdf}{\ref*{obs.month}} and 
Figure \href{../plots/obs_month_byseason.pdf}{\ref*{obs.month.season}} both 
indicate there is a significant drop of observation count on Jan 1982. And among 
the 16 years after that, January always has the lowest observation count.

Moreover, we found that this drop on Jan 1982 is not caused by adjustment of 
location of the stations, such as one station shift its location to its 
neighborhood. It is because the 688 stations were missing observation on Jan 
1982, but then they were active again on Feb 1982, as shown in Figure 
\href{../plots/obs_Jan1982.pdf}{\ref*{Jan1982}}. The blue circles represent 
stations whose status were changed to be missing from December 1981
to January 1982. Meanwhile the magenta solid points represent stations whose
observation status switched back to be valid from January 1982 to February 1982.
If a location has both blue circle and magenta solid point, it means that weather 
station suddenly failed on January 1982, but then went back to normal on 
February 1982. 

\begin{framed}
\begin{center}
  \href{../plots/obs_Jan1982.pdf}{Link to figure}
  \captionof{figure}{The location of active stations around Jan 1982}
  \label{Jan1982}
\end{center}
\end{framed}

We believe this astonishing number of failure of stations on January 1982 is caused
by severe weather, which may have caused the battery in the weather station to 
die. From January 11 to January 17, A brutal cold snap sends temperatures to 
record lows in dozens of cities throughout the Midwestern United States.
Especially on January 17, 1982, so called "Cold Sunday"\cite{coldsunday}, in 
numerous cities temperatures fall to their lowest levels in over 100 years.

\subsection{Subset after Year 1950}

As shown in the Figure \href{../plots/obs_month.pdf}{\ref*{obs.month}}, we notice
the number of active stations gradually stabilized after Jan 1950. Since long
period of missing observation is not the main concern of this thesis, we decide
only consider stations with observations after Jan 1950.

\subsubsection{Location of Stations}

Figure \href{../plots/a1950stations.pdf}{\ref*{a1950.location}} illustrates the 
location of 7,738 stations on the map of United States.

\begin{framed}
\begin{center}
  \href{../plots/a1950stations.pdf}{Link to figure}
  \captionof{figure}{The location of stations after 1950}
  \label{a1950.location}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/tmax.a1950.status.pdf}
  {Link to figure}
  \captionof{figure}{The observation status of stations in each month}
  \label{a1950.status}
\end{center}
\end{framed}

For each month, it is a spatial regularization of observation of maximum 
temperature over 7,738 locations. But around 2,000 stations have 
missing value in each month. For instance, in Figure 
\href{../plots/tmax.a1950.status.pdf}{\ref*{a1950.status}},
we illustrate the observation status of 7,738 stations for all 576 months.

As we will see in later sections, diagnostic plots play a critical rule in our
analysis. However it is not feasible to visualize the analytic results of all
7,738 stations for example. A natural approach to compromise this issue is to 
visualize a reasonable part of all stations. Randomly sampling stations may be
plausible, but it is likely that we sampled stations densely or sparsely in a 
specific region on the map. In order to get well presentation of all stations,
a sampling procedure is proposed based on near exactly replicate.

As shown in Figure \href{../plots/vertices.a1950.pdf}{\ref*{a1950.vertices}}
A kd-tree with 512 cells is built based on 7,738 stations. Then one station is 
sampled from each cell randomly. The blue dots on the graph show the locations 
of these 512 sampled stations. An index number from 1 to 512 is assigned to each 
station to illustrate which cell the station comes from. 

\begin{framed}
\begin{center}
  \href{../plots/vertices.a1950.pdf}{Link to figure}
  \captionof{figure}{The location of 512 stations sampled from each cell of a kd-tree}
  \label{a1950.vertices}
\end{center}
\end{framed}

We also graph the quantile plot of the log base 2 of elevation of stations in each
cell in Figure \href{../plots/elev.dist.bycell.pdf}{\ref*{elev.dist.bycell}}. 
The elevation in majority of the 512 cells varies in a very limited range. However, 
some of the cells, such as cells 3, 4, 6, 9, 17, 18, in which stations are 
concentrated in the area of west coast of the United State. The distribution of 
elevation has a much more expanded range than that in the area of the central 
United States. 

\begin{framed}
\begin{center}
  \href{../plots/elev.dist.bycell.pdf}{Link to figure}
  \captionof{figure}{The quantiles of elevation of stations conditional on cell}
  \label{elev.dist.bycell}
\end{center}
\end{framed}

\subsubsection{The number of observation}

As shown in Figure \href{../plots/tmax.a1950.status.pdf}{\ref*{a1950.status}},
the location of stations with missing values are relatively sparse and random.
There is not a region filled up with all missing values. However the missing
value is not quite random in the time dimension. Here we provide visualization 
evidence about the high rate of missing value in each station.

\begin{framed}
\begin{center}
  \href{../plots/a1950/a1950.obs.station.pdf}{Link to figure}
  \captionof{figure}{The quantiles of number of observation in one station}
  \label{quant.obs}
\end{center}
\end{framed}

\begin{framed}
\begin{center}
  \href{../plots/a1950/a1950.obsrate.station.pdf}{Link to figure}
  \captionof{figure}{The quantiles of rate of valid observation number in one 
  station}
  \label{quant.obsrate}
\end{center}
\end{framed}

In Figure \href{../plots/a1950/a1950.obs.station.pdf}{\ref*{quant.obs}}, the 
number of observation for each station, in log base 2, is plotted against to 
corresponding f-value. Only less than 20 percent of stations do not have missing
value during that 576 months. Meanwhile, about 30 percent of stations have only
256 or less observations in total. It is about 40 percent of total observations 
for a station based on the Figure 
\href{../plots/a1950/a1950.obsrate.station.pdf}{\ref*{quant.obsrate}}, in which 
the rate of valid observation of each station is drawn against to the 
corresponding f-value.

If the missing values of each station are sparse only, we still can handle them 
by \texttt{stlplus} function in R. However, as shown in Figure 
\href{../plots/a1950/a1950.consecutive.miss.station.pdf}
{\ref*{quant.consecutivemiss}}, more than 20 percent of stations have maximum 
length of consecutive missing values longer than 16, which is more than a year. 

\begin{framed}
\begin{center}
  \href{../plots/a1950/a1950.consecutive.miss.station.pdf}{Link to figure}
  \captionof{figure}{The quantiles of maximum length of consecutive missing value}
  \label{quant.consecutivemiss}
\end{center}
\end{framed}

Based on the property of the missing value in the dataset, it is recommended to
start the analysis from the spatial dimension. We divide the data into 
by month division first. In the next section, we demonstrate how to generate the
by month division, and how the spatial fitting is applied to the division.